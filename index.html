<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mind Uploading Research | マインドアップロード実現への道</title>
    <meta name="description" content="マインドアップロード実現のための中核となるコアサイト。意識や記憶の交換・複製を可能とする技術の研究とコミュニティの中心的ハブ。">
    <meta property="og:title" content="EEGFlow | マインドアップロード実現への道">
    <meta property="og:description" content="マインドアップロード実現のための中核となるコアサイト。意識や記憶の交換・複製を可能とする技術の研究とコミュニティの中心的ハブ。">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://eegflow.jp">
    <meta property="og:image" content="https://eegflow.jp/ogp.jpg">
    <meta name="twitter:card" content="summary_large_image">
    <link rel="icon"
        href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🧠</text></svg>">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=Source+Sans+3:wght@400;600;700&display=swap"
        rel="stylesheet">
    <style>
        :root {
            --font-serif: 'Libre Baskerville', 'Times New Roman', serif;
            --font-sans: 'Source Sans 3', 'Helvetica Neue', sans-serif;
            --color-bg: #0d0d0f;
            --color-paper: #161618;
            --color-text: #e8e8ec;
            --color-text-secondary: #a8a8b0;
            --color-text-muted: #6a6a75;
            --color-accent: #ef5350;
            --color-accent-dark: #c62828;
            --color-link: #64b5f6;
            --color-border: #2a2a30;
            --color-sidebar: #1a1a1e;
            --max-width: 1100px;
            --column-gap: 40px;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: var(--font-serif);
            font-size: 16px;
            line-height: 1.75;
            color: var(--color-text);
            background: var(--color-bg);
        }

        /* Header Bar */
        .journal-header {
            background: var(--color-accent);
            color: white;
            padding: 8px 20px;
            font-family: var(--font-sans);
            font-size: 12px;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .journal-header a {
            color: white;
            text-decoration: none;
        }

        .journal-header a:hover {
            text-decoration: underline;
        }

        /* Title Section */
        .article-header {
            max-width: var(--max-width);
            margin: 0 auto;
            padding: 40px 20px 30px;
            border-bottom: 2px solid var(--color-text);
        }

        .article-type {
            font-family: var(--font-sans);
            font-size: 12px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.15em;
            color: var(--color-accent);
            margin-bottom: 12px;
        }

        .article-title {
            font-size: 32px;
            font-weight: 700;
            line-height: 1.25;
            margin-bottom: 16px;
            color: var(--color-text);
        }

        .article-subtitle {
            font-size: 18px;
            font-style: italic;
            color: var(--color-text-secondary);
            margin-bottom: 20px;
        }

        .author-info {
            font-family: var(--font-sans);
            font-size: 14px;
            color: var(--color-text-secondary);
            margin-bottom: 8px;
        }

        .author-name {
            font-weight: 600;
            color: var(--color-text);
        }

        .article-meta {
            font-family: var(--font-sans);
            font-size: 12px;
            color: var(--color-text-muted);
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
            margin-top: 12px;
        }

        /* Main Layout */
        .main-container {
            max-width: var(--max-width);
            margin: 0 auto;
            display: grid;
            grid-template-columns: 1fr 280px;
            gap: var(--column-gap);
            padding: 30px 20px;
        }

        .content-column {
            min-width: 0;
        }

        .sidebar-column {
            font-family: var(--font-sans);
        }

        /* Content Styles */
        .section {
            margin-bottom: 30px;
        }

        .section-title {
            font-family: var(--font-sans);
            font-size: 13px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            color: var(--color-accent);
            margin-bottom: 12px;
            padding-bottom: 6px;
            border-bottom: 1px solid var(--color-border);
        }

        .section h3 {
            font-size: 18px;
            font-weight: 700;
            margin: 20px 0 10px;
            color: var(--color-text);
        }

        .section p {
            margin-bottom: 12px;
            text-align: justify;
        }

        /* Abstract Box */
        .abstract-box {
            background: var(--color-paper);
            border-left: 4px solid var(--color-accent);
            padding: 20px 24px;
            margin-bottom: 30px;
        }

        .abstract-box h2 {
            font-family: var(--font-sans);
            font-size: 12px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            color: var(--color-accent);
            margin-bottom: 10px;
        }

        .abstract-box p {
            font-size: 15px;
            line-height: 1.7;
            color: var(--color-text-secondary);
        }

        /* Key Points / Highlights */
        .key-points {
            background: var(--color-sidebar);
            padding: 20px;
            margin-bottom: 24px;
            border-radius: 4px;
        }

        .key-points h4 {
            font-size: 12px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.08em;
            color: var(--color-accent);
            margin-bottom: 12px;
        }

        .key-points ul {
            list-style: none;
            padding: 0;
        }

        .key-points li {
            font-size: 13px;
            line-height: 1.6;
            padding: 6px 0;
            padding-left: 16px;
            position: relative;
            border-bottom: 1px solid var(--color-border);
        }

        .key-points li:last-child {
            border-bottom: none;
        }

        .key-points li::before {
            content: '▸';
            position: absolute;
            left: 0;
            color: var(--color-accent);
            font-size: 10px;
        }

        /* Figure Box */
        .figure-box {
            background: var(--color-paper);
            padding: 16px;
            margin: 24px 0;
            border: 1px solid var(--color-border);
        }

        .figure-box .figure-content {
            background: white;
            padding: 20px;
            text-align: center;
            margin-bottom: 12px;
        }

        .figure-box .figure-label {
            font-family: var(--font-sans);
            font-size: 11px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--color-text);
            margin-bottom: 6px;
        }

        .figure-box .figure-caption {
            font-family: var(--font-sans);
            font-size: 12px;
            color: var(--color-text-secondary);
            text-align: left;
            line-height: 1.5;
        }

        /* Timeline/Progress Figure */
        .timeline-visual {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            padding: 10px 0;
            position: relative;
        }

        .timeline-visual::before {
            content: '';
            position: absolute;
            top: 28px;
            left: 40px;
            right: 40px;
            height: 2px;
            background: linear-gradient(to right, var(--color-accent), var(--color-border));
        }

        .timeline-item {
            text-align: center;
            flex: 1;
            position: relative;
            z-index: 1;
        }

        .timeline-dot {
            width: 16px;
            height: 16px;
            border-radius: 50%;
            background: var(--color-border);
            border: 2px solid white;
            margin: 20px auto 10px;
        }

        .timeline-dot.done {
            background: var(--color-accent);
        }

        .timeline-dot.current {
            background: white;
            border: 2px solid var(--color-accent);
            box-shadow: 0 0 0 3px rgba(183, 28, 28, 0.2);
        }

        .timeline-label {
            font-family: var(--font-sans);
            font-size: 11px;
            color: var(--color-text-secondary);
            line-height: 1.4;
        }

        /* Stage Cards */
        .stage-list {
            counter-reset: stage;
        }

        .stage-item {
            display: flex;
            gap: 16px;
            padding: 16px 0;
            border-bottom: 1px solid var(--color-border);
        }

        .stage-item:last-child {
            border-bottom: none;
        }

        .stage-number {
            counter-increment: stage;
            font-family: var(--font-sans);
            font-size: 24px;
            font-weight: 700;
            color: var(--color-accent);
            min-width: 40px;
        }

        .stage-number::before {
            content: counter(stage);
        }

        .stage-body h4 {
            font-family: var(--font-sans);
            font-size: 14px;
            font-weight: 700;
            margin-bottom: 6px;
            color: var(--color-text);
        }

        .stage-body p {
            font-size: 14px;
            line-height: 1.6;
            margin-bottom: 8px;
        }

        .tag-list {
            display: flex;
            flex-wrap: wrap;
            gap: 6px;
        }

        .tag {
            font-family: var(--font-sans);
            font-size: 10px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            padding: 3px 8px;
            background: var(--color-paper);
            border: 1px solid var(--color-border);
            color: var(--color-text-secondary);
        }

        /* Table Styles */
        .data-table {
            width: 100%;
            border-collapse: collapse;
            font-family: var(--font-sans);
            font-size: 13px;
            margin: 16px 0;
        }

        .data-table th {
            background: var(--color-paper);
            font-weight: 700;
            text-align: left;
            padding: 10px 12px;
            border-bottom: 2px solid var(--color-text);
            font-size: 11px;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }

        .data-table td {
            padding: 10px 12px;
            border-bottom: 1px solid var(--color-border);
            vertical-align: top;
        }

        .data-table td:first-child {
            font-weight: 700;
            color: var(--color-accent);
            white-space: nowrap;
        }

        /* Sidebar Styles */
        .sidebar-box {
            background: var(--color-sidebar);
            padding: 16px;
            margin-bottom: 20px;
            border-radius: 4px;
        }

        .sidebar-box h4 {
            font-size: 11px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.08em;
            color: var(--color-accent);
            margin-bottom: 12px;
            padding-bottom: 8px;
            border-bottom: 1px solid var(--color-border);
        }

        .sidebar-box p,
        .sidebar-box li {
            font-size: 12px;
            line-height: 1.6;
            color: var(--color-text-secondary);
        }

        .sidebar-box ul {
            list-style: none;
            padding: 0;
        }

        .sidebar-box li {
            padding: 4px 0;
            padding-left: 12px;
            position: relative;
        }

        .sidebar-box li::before {
            content: '•';
            position: absolute;
            left: 0;
            color: var(--color-accent);
        }

        /* Links */
        a {
            color: var(--color-link);
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        sup a {
            font-size: 11px;
            vertical-align: super;
        }

        /* Call to Action */
        .cta-box {
            background: var(--color-accent);
            color: white;
            padding: 20px;
            text-align: center;
            margin: 24px 0;
        }

        .cta-box h4 {
            font-family: var(--font-sans);
            font-size: 14px;
            font-weight: 700;
            margin-bottom: 8px;
        }

        .cta-box p {
            font-size: 13px;
            margin-bottom: 12px;
            opacity: 0.9;
        }

        .cta-box a {
            display: inline-block;
            font-family: var(--font-sans);
            font-size: 12px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            padding: 10px 24px;
            background: white;
            color: var(--color-accent);
            text-decoration: none;
            transition: all 0.2s;
        }

        .cta-box a:hover {
            background: var(--color-paper);
            text-decoration: none;
        }

        /* References Section */
        .references {
            font-size: 12px;
            line-height: 1.7;
        }

        .references ol {
            padding-left: 24px;
        }

        .references li {
            margin-bottom: 8px;
            color: var(--color-text-secondary);
        }

        .references em,
        .references i {
            font-style: italic;
            color: var(--color-text);
        }

        /* Footer */
        footer {
            background: var(--color-text);
            color: white;
            padding: 24px 20px;
            font-family: var(--font-sans);
            font-size: 12px;
            text-align: center;
        }

        footer a {
            color: white;
            text-decoration: underline;
        }

        /* Note Box */
        .note-box {
            background: #2a2518;
            border-left: 3px solid #ffc107;
            padding: 12px 16px;
            margin: 16px 0;
            font-size: 14px;
        }

        .note-box strong {
            font-family: var(--font-sans);
            font-size: 12px;
            text-transform: uppercase;
            color: #ffca28;
        }

        /* Question Box */
        .question-box {
            border: 1px solid var(--color-border);
            padding: 16px;
            margin: 12px 0;
        }

        .question-box h4 {
            font-family: var(--font-sans);
            font-size: 14px;
            font-weight: 700;
            margin-bottom: 8px;
            color: var(--color-text);
        }

        .question-box p {
            font-size: 14px;
            color: var(--color-text-secondary);
            margin: 0;
        }

        .resolution-box {
            border: 1px solid #2f3b2f;
            background: #182018;
            padding: 14px 16px;
            margin-top: 10px;
            border-left: 3px solid #7cb342;
        }

        .resolution-box h5 {
            font-family: var(--font-sans);
            font-size: 13px;
            font-weight: 700;
            color: #c5e1a5;
            margin-bottom: 6px;
        }

        .resolution-box p {
            font-size: 13px;
            color: #d7e2cf;
            margin: 0;
            line-height: 1.5;
        }

        /* Responsive */
        @media (max-width: 900px) {
            .main-container {
                grid-template-columns: 1fr;
            }

            .sidebar-column {
                order: -1;
                display: grid;
                grid-template-columns: 1fr 1fr;
                gap: 16px;
            }
        }

        @media (max-width: 600px) {
            .article-title {
                font-size: 24px;
            }

            .sidebar-column {
                grid-template-columns: 1fr;
            }

            .timeline-visual {
                flex-direction: column;
                gap: 16px;
                align-items: flex-start;
            }

            .timeline-visual::before {
                display: none;
            }

            .timeline-item {
                display: flex;
                align-items: center;
                gap: 12px;
                text-align: left;
            }

            .timeline-dot {
                margin: 0;
            }
        }
    </style>
</head>

<body>

    <!-- Journal Header -->
    <header class="journal-header">
        <span>Mind Uploading Research Notes</span>
        <a href="https://github.com/yasufumi-nakata/eegflow" target="_blank">GitHub Repository →</a>
    </header>

    <!-- Article Header -->
    <header class="article-header">
        <p class="article-type">Perspective</p>
        <h1 class="article-title">マインドアップロード実現への道：技術・理論・倫理の統合アプローチ</h1>
        <p class="article-subtitle">脳の情報処理を別の基盤で再現し、心的機能を移植・複製するという研究仮説の現状と展望</p>
        <p class="author-info">
            <span class="author-name">Mind Uploading Research Project</span>
        </p>
        <div class="article-meta">
            <span>Open Access</span>
            <span>Last Updated: 2026-01-12</span>
            <span>研究ノート (2026年1月改訂)</span>
        </div>
    </header>

    <!-- Main Content -->
    <main class="main-container">
        <article class="content-column">

            <!-- Abstract -->
            <div class="abstract-box">
                <h2>Abstract</h2>
                <p>マインドアップロード（Whole Brain Emulation, WBE）は、脳の情報処理とそれに伴う心的機能を、生物学的基盤から計算機等の別基盤へ移植・再現する研究領域である<sup><a href="#ref-2">[2]</a></sup>。本稿ではこの壮大な課題を、(1)計測、(2)解読、(3)実装の3段階の技術的フレームワークで整理し、各段階における最新の学術的知見と未解決の課題を批判的に検討する。特に、意識の統合情報理論（IIT 4.0）<sup><a href="#ref-17">[17]</a></sup>やNTTによるMind Captioning技術<sup><a href="#ref-11">[11]</a></sup>といった最新トピックを、その理論的・技術的限界と共に論じる。IITが直面する計算量の問題や反証可能性に関する批判<sup><a href="#ref-1">[1]</a></sup>、デコーディング技術とエミュレーションの間の論理的飛躍など、楽観的な技術論では見過ごされがちな課題を直視し、より厳密で実現可能な研究計画を提案する。本稿は、これらの技術的・理論的課題に加え、デレク・パーフィットの心理的連続性理論<sup><a href="#ref-4">[4]</a></sup>に端を発する哲学的問題や、MIND Act of 2025<sup><a href="#ref-24">[24]</a></sup>に代表される法的・倫理的課題を統合的に概観し、今後の研究の方向性を提示する。</p>
            </div>

            <!-- Introduction -->
            <section class="section">
                <h2 class="section-title">Introduction</h2>

                <h3>1.1. 理論的枠組みの厳密性と批判的視点</h3>
                <p>マインドアップロードの本人性検証において、決定的な単一の理論は存在しない。本プロジェクトは複数の理論的支柱を批判的に検討・採用する。第一に、ジュリオ・トノーニらが提唱する<strong>意識の統合情報理論（IIT 4.0）</strong><sup><a href="#ref-17">[17]</a></sup>である。IITは意識の「量」（統合情報量Φ）を測定する枠組みを提供するが、それが直ちに「個人の同一性（Identity）」を保証するものではない。因果構造が相同であっても、それが「私」という主観的経験の連続性を担保するかは別問題である。</p>
                <p>この飛躍の根拠として、IITのような因果構造理論が直面する<strong>「Unfolding Argument」</strong><sup><a href="#ref-40">[40]</a></sup>という根源的な批判がある。これは、因果構造のみに依存する理論が、機能的に等価なフィードフォワード網（Unfoldすれば意識がないとされる）と再帰網（意識があるとされる）を区別できないという矛盾を指摘するものである。したがって、「因果的相同性」を本人性維持の決定的な指標として扱うことは理論的飛躍であり、あくまで検証されるべき仮説の一つとして位置づける。IITの計算困難性や反証可能性の欠如といった課題<sup><a href="#ref-1">[1]</a></sup>も踏まえ、機能主義的アプローチや、第二の支柱であるParfitの心理的連続性理論との整合性をより慎重に議論する必要がある。</p>

                <p>第二の支柱は、哲学者デレク・パーフィットによる<strong>心理的連続性理論</strong><sup><a href="#ref-4">[4]</a></sup>である。これは、記憶や性格といった心理的特徴の重なりと連続によって個人の同一性が維持されるとする考え方である。マインドアップロードの文脈では、これは「アップロードされた意識がオリジナルと同一か？」という問いに答えるための重要な視点を提供する。しかし、これは同時に「コピー問題（分身のパラドックス）」という工学的に困難な課題を提起する。単なる情報の構造的保存率といった静的な指標だけでは不十分であり、意識が途切れないと感じられる「プロセス」の連続性をいかに保証するかが鍵となる。これには、段階的な神経置換や、生物学的脳と人工脳が連携するハイブリッドシステムにおけるリアルタイム検証など、動的な心理的連続性を担保する具体的なプロトコルの設計が不可欠となる。</p>

                <div class="note-box">
                    <strong>研究としての約束</strong>
                    <p>以下を「最低限のガードレール」として運用する：主要な主張には一次/総説などの出典を付す・仮説と事実、価値判断を区別し不確実性を併記する・評価指標や手順を先に定義し再現可能性を優先する。</p>
                </div>
            </section>


            <!-- Technical Framework -->
            <section class="section">
                <h2 class="section-title">Technical Framework</h2>

                <p>マインドアップロードの実現に向けた技術的ロードマップは、「計測」「解読」「実装」の3段階で構想される。</p>

                <div class="stage-list">
                    <div class="stage-item">
                        <div class="stage-number"></div>
                        <div class="stage-body">
                            <h4>1. 計測（Sensing）：脳活動の精密な読み取り</h4>
                            <p>高時間分解能を持つ高密度脳波（HD-EEG）と脳波源推定（ESI）の統合は有望ですが、ESIで空間分解能の限界を「克服」できるという見方は、実験神経科学の観点からは楽観的すぎます。ESIはあくまで**推定**であり、その精度は電極数だけでなく、個別の頭部モデルの正確性に強く依存します<sup><a href="#ref-5">[5]</a></sup>。特に深部脳領域の活動や、近接する皮質領域の分離には限界があります。その基盤となる「逆問題」は、本質的に解が一意に定まらない**不良設定問題（ill-posed problem）**であるという根本的課題を抱えています。</p>
                            <p>この課題に対処し、学術的な厳密性を担保するためには、単に最新手法を適用するだけでなく、以下のプロトコルの導入が不可欠です。</p>
                            <ul style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px; line-height: 1.6;">
                                <li style="margin-bottom: 8px;"><strong>個別化頭部モデル（IHM）：</strong>MRI/CTデータから個人の頭部構造を忠実にモデル化し、信号伝達の精度を向上させることが必須です<sup><a href="#ref-5">[5]</a></sup>。</li>
                                <li style="margin-bottom: 8px;"><strong>fMRI/MEGとのクロスバリデーション：</strong>空間分解能に優れたfMRIや、磁場を計測するMEGの情報を統合して時空間的な制約を加えるだけでなく、それらを推定結果の妥当性を検証する「グラウンドトゥルース」として用いることを必須要件とします。</li>
                                <li style="margin-bottom: 8px;"><strong>推定の不確実性の明示：</strong>ベイズ推定に基づく事後確率分布や信頼区間（Confidence Interval）を計算し、推定結果の不確実性を常に可視化・定量化するプロトコルを導入します。</li>
                                <li style="margin-bottom: 8px;"><strong>逆問題制約条件の妥当性検証：</strong>LORETA、sLORETA、MNEといった制約（アルゴリズム）の選択が結果に与える影響は甚大です。その選択理由を明確にし、シミュレーションによる妥当性検証プロトコルを確立します。</li>
                            </ul>
                            <div class="tag-list" style="margin-top: 12px;">
                                <span class="tag">HD-EEG</span>
                                <span class="tag">ESI (Source Imaging)</span>
                                <span class="tag">個別化頭部モデル (IHM)</span>
                                <span class="tag">マルチモーダル融合 (MEG/fMRI)</span>
                            </div>
                        </div>
                    </div>
                    <div class="stage-item">
                        <div class="stage-number"></div>
                        <div class="stage-body">
                            <h4>2. 解読（Decoding）：脳情報から心的内容へ</h4>
                            <p>NTTによる「Mind Captioning」<sup><a href="#ref-11">[11]</a></sup>は、脳活動から思考内容を記述する技術の大きな進展を示すが、これを脳情報の「解読」と見なすのは危険な解釈である。現在の技術は、脳活動と自然言語の<strong>相関</strong>を学習した生成モデルであり、脳内の情報表現そのものを忠実に「解読」しているわけではない。Horikawaらの原論文においても、生成されたテキストのセマンティックな一致度は高いが、それが個人の主観的経験の「忠実な再現」であるかについては検証の余地があると慎重な姿勢が示されている。むしろ、この技術は「翻訳的推論（Translational Inference）」と呼ぶのが適切であり、LLMが時に事実に基づかない「もっともらしい」テキストを生成するハルシネーションと同様のリスクを内包している<sup><a href="#ref-11">[11]</a></sup>。</p>
                            <p>WBEが目指すのは、この「記述（Description）」の成功に留まらず、情報が処理され意識的経験を生み出す「**因果ダイナミクス**（How）」の再現である<sup><a href="#ref-7">[7]</a></sup>。この論理的飛躍を埋めるため、本プロジェクトは生成された内容の「因果的整合性」を検証する具体的なベンチマーク（例：介入実験）を導入する。具体的には、デコーディングで得られたモデルに対し、<strong>Dynamic Causal Modeling (DCM)</strong><sup><a href="#ref-13">[13]</a></sup>のような手法を用いて、元の脳の因果的結合（有効結合性）をどの程度再現しているかを定量的に評価し、エミュレーションの妥当性を測る検証指標とする。</p>
                             <div class="note-box" style="margin: 16px 0;">
                                <strong>課題: LLMによる「思考の特異性」の平均化リスク</strong>
                                <p>現在のデコーディング手法は、脳活動データを一度LLMが解釈可能な特徴量空間に射影し、そこから言語を生成する。このプロセスには、個人の思考が持つ「特異性」や「曖昧さ」が、LLMの学習データに存在する言語的・文化的バイアスによって「平均化」されてしまうという本質的なリスクが内在する。情報理論的に言えば、これはデコーディング過程における情報損失に他ならない。このバイアスを定量化し、補正する枠組みの構築が、真に個人の精神を保存する上で不可欠の課題となる。</p>
                            </div>
                            <div class="tag-list">
                                <span class="tag">Mind Captioning</span>
                                <span class="tag">デコーディング vs エミュレーション</span>
                                <span class="tag">因果ダイナミクス (DCM)</span>
                                <span class="tag">Transformer</span>
                            </div>
                        </div>
                    </div>
                    <div class="stage-item">
                        <div class="stage-number"></div>
                        <div class="stage-body">
                            <h4>3. 実装（Implementation）：意識の再起動と本人性検証</h4>
                            <p>解読された脳情報を新たな基盤で動作させる段階では、WBA（Whole Brain Architecture）<sup><a href="#ref-15">[15]</a></sup>等のアーキテクチャが構想されている。この段階での核心的課題は、Parfitの心理的連続性理論<sup><a href="#ref-4">[4]</a></sup>に基づき、「構造の保存」が「主観的連続性」をいかに保証するかを操作的に定義し、検証することである。</p>
                             <p>当初、本人性検証の定量的指標として、IIT 4.0における「因果的相同性」<sup><a href="#ref-17">[17]</a></sup>が有力視された。しかし、このアプローチは計算量の爆発や非一意性問題<sup><a href="#ref-3">[3]</a></sup>といった数学的課題、さらには反証可能性に乏しいという科学哲学上の批判<sup><a href="#ref-1">[1]</a></sup>に直面している。これらの課題は深刻であり、IITを唯一の根拠とすることはできない。</p>
                            <p>このギャップを埋めるため、本研究では「因果的相同性」を直接的な計測指標とするのではなく、より工学的に近似可能な**「マクロスケールでの有効連結性の保存」**を代替指標として提案する。具体的には、DCM<sup><a href="#ref-13">[13]</a></sup>を用いて「元の脳」と「エミュレーション」それぞれの有効連結性マップを作成し、その統計的類似性を評価することで、「本人性」の連続性を工学的に検証する道筋を立てる。これは、IITの理念を尊重しつつも、計算論的制約を回避し、経験的に検証可能なマイルストーンを設定する現実的なアプローチである。</p>
                            <div class="tag-list">
                                <span class="tag">WBA (全脳アーキテクチャ)</span>
                                <span class="tag">有効連結性 (DCM)</span>
                                <span class="tag">心理的連続性理論</span>
                                <span class="tag">本人性ベンチマーク</span>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Reproducibility -->
            <section class="section">
                <h2 class="section-title">プロジェクトの実体性と再現性 (Substance and Reproducibility)</h2>
                <p>「EEGFlow」というプロジェクト名が示す通り、本研究は計算論的手法に基づいている。しかし、現状のGitHubリポジトリにはウェブサイト関連ファイルしか存在せず、研究プロジェクトとしての実体性・再現性が欠如しているとの批判は免れない。この重大な懸念に応えるため、今後は以下の要素を段階的にリポジトリに追加し、ウェブサイトの主張を裏付けるコードベースを構築する。</p>
                <ul style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px; line-height: 1.6;">
                    <li style="margin-bottom: 8px;"><strong>データ処理パイプライン：</strong>BIDS準拠の生データから、ESI、DCM解析に至るまでの最小限実行可能な処理スクリプト（Python/MNE-Python, SPM, FieldTrip等のラッパー）を公開する。</li>
                    <li style="margin-bottom: 8px;"><strong>デコーディングモデル：</strong>Mind Captioningに類するTransformerベースのモデルアーキテクチャ定義と、ダミーデータを用いた学習・推論コードを公開する。</li>
                    <li style="margin-bottom: 8px;"><strong>データスキーマの拡充：</strong>`dataset_description.json`に加え、EEGデータの具体的な構造（例：`sub-01/eeg/sub-01_task-rest_eeg.eeg`）や、計測プロトコルを記述した`eeg.json`のスキーマ例を公開し、BIDS標準の形式的遵守から実質的遵守へと移行する。</li>
                </ul>
            </section>

            <!-- Reproducibility -->
            <section class="section">
                <h2 class="section-title">プロジェクトの実体性と再現性 (Substance and Reproducibility)</h2>
                <p>「EEGFlow」というプロジェクト名が示す通り、本研究は計算論的手法に基づいている。しかし、現状のGitHubリポジトリにはウェブサイト関連ファイルしか存在せず、研究プロジェクトとしての実体性・再現性が欠如しているとの批判は免れない。この重大な懸念に応えるため、今後は以下の要素を段階的にリポジトリに追加し、ウェブサイトの主張を裏付けるコードベースを構築する。</p>
                <ul style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px; line-height: 1.6;">
                    <li style="margin-bottom: 8px;"><strong>データ処理パイプライン：</strong>BIDS準拠の生データから、ESI、DCM解析に至るまでの最小限実行可能な処理スクリプト（Python/MNE-Python, SPM, FieldTrip等のラッパー）を公開する。</li>
                    <li style="margin-bottom: 8px;"><strong>デコーディングモデル：</strong>Mind Captioningに類するTransformerベースのモデルアーキテクチャ定義と、ダミーデータを用いた学習・推論コードを公開する。</li>
                    <li style="margin-bottom: 8px;"><strong>データスキーマの拡充：</strong>`dataset_description.json`に加え、EEGデータの具体的な構造（例：`sub-01/eeg/sub-01_task-rest_eeg.eeg`）や、計測プロトコルを記述した`eeg.json`のスキーマ例を公開し、BIDS標準の形式的遵守から実質的遵守へと移行する。</li>
                </ul>
            </section>

            <!-- Current Status -->
            <section class="section">
                <h2 class="section-title">主要な技術的課題 (Key Technical Challenges)</h2>

                <h3>コネクトームとダイナミクスのギャップ</h3>
                <p>図1が示す構造的コネクトーム（神経配線図）の研究は大きく進展しているが、それだけでは脳の動的な活動を説明するには不十分である。脳機能は、主に2つの理由から、静的な配線図以上のものを要求する。第一に、脳の機能状態は、シナプス結合だけでなく、ドーパミンやセロトニンといった神経修飾物質が脳全体に拡散して作用する「体積伝導（Volume Transmission）」によっても大きく左右される<sup><a href="#ref-39">[39]</a></sup>。第二に、これまで補助細胞と見なされてきた<strong>非神経細胞（特にアストロサイト）の役割が過小評価されている</strong>。近年の研究は、アストロサイトが神経伝達物質を感知・放出し、シナプス可塑性や情報処理の時定数を能動的に制御する「三者系シナプス（Tripartite Synapse）」の不可欠な構成要素であることを示している<sup><a href="#ref-41">[41]</a></sup>。</p>
                <p>このことは、脳のエミュレーションが、単なるニューロンの接続性（コネクトーム）の再現に留まらず、神経修飾状態やグリア細胞による変調ダイナミクスといった、より複雑な動的要素を第一級のパラメータとして組み込む必要があることを意味する。この静的な構造と動的な状態の間のギャップを埋めるため、将来的には遺伝子発現情報から神経接続の特性を推定する「トランスクリプトーム・コネクトミクス」や、神経修飾状態をマッピングする動的な状態遷移モデルをフレームワークに統合する必要がある。</p>

                <!-- Figure: Connectome Progress -->
                <div class="figure-box">
                    <div class="figure-content">
                        <div class="timeline-visual">
                            <div class="timeline-item">
                                <div class="timeline-dot done"></div>
                                <div class="timeline-label">線虫<br><strong>302</strong> neurons</div>
                            </div>
                            <div class="timeline-item">
                                <div class="timeline-dot done"></div>
                                <div class="timeline-label">ショウジョウバエ<br><strong>~25,000</strong> neurons</div>
                            </div>
                            <div class="timeline-item">
                                <div class="timeline-dot current"></div>
                                <div class="timeline-label">マウス<br><strong>~71M</strong> neurons</div>
                            </div>
                            <div class="timeline-item">
                                <div class="timeline-dot"></div>
                                <div class="timeline-label">ヒト<br><strong>~86B</strong> neurons</div>
                            </div>
                        </div>
                    </div>
                    <p class="figure-label">Figure 1</p>
                    <p class="figure-caption">コネクトーム研究の進展とスケール。線虫（<em>C. elegans</em>）やショウジョウバエでは完全な構造的コネクトームが解明されているが、機能的ダイナミクスの解明は依然課題である。マウスのニューロン数は約7100万であり、コネクトーム解析は現在進行中である。ヒト脳は約860億ニューロンを有する。
                    </p>
                </div>
            </section>

            <!-- Research Program -->
            <section class="section">
                <h2 class="section-title">Research Program</h2>

                <p>論文化を意識した実証プランでは、計測・解読・実装の各段階を統合的に示す。目標はマルチモーダル計測と神経解読を統合した「本人性維持」評価系の設計と論文化である。</p>

                <!-- Table: Roadmap -->
                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Phase</th>
                            <th>計測/データ</th>
                            <th>解読/解析</th>
                            <th>実装/倫理</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>1</td>
                            <td>HD-EEG/fMRI同時計測セットアップ、再現性データ収集。IHM採用とBIDSメタデータ拡充。</td>
                            <td>Transformerベースのデコーディングに加え、LLM由来ノイズを定量化する「因果的整合性チェック」プロトコルの導入。</td>
                            <td>MIND Act 2025準拠の同意プロセス、神経データプライバシー保護設計。</td>
                        </tr>
                        <tr>
                            <td>2</td>
                            <td>ESI信号分離とMEGデータの融合。逆問題制約条件の妥当性検証。</td>
                            <td>Dynamic Causal Modeling (DCM) による部位間因果ダイナミクス解析。</td>
                            <td>心理的連続性理論に基づく「本人性」評価指標の操作的定義と、コピー問題への工学的アプローチの検討。</td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td>WBA統合フレームワークでの動作検証。非神経細胞（グリア）のモデル化。</td>
                            <td>DCMを用いた「元の脳」と「エミュレーション」の有効連結性比較による本人性検証。</td>
                            <td>Neurorightsに基づく権利枠組み、デジタル遺産・継承権の法的整備。</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <!-- Legal and Ethical Framework -->
            <section class="section">
                <h2 class="section-title">法的・倫理的枠組みの具体化 (Legal & Ethical Specification)</h2>
                <p>本研究は技術開発と並行し、法的・倫理的課題の具体的な検討を不可分の一部と見なす。特に、以下の2つの論点を深く掘り下げる。</p>
                <h3>MIND Act 2025 と Neurorights の拡張</h3>
                <p>米国で提案された「MIND Act of 2025」<sup><a href="#ref-24">[24]</a></sup>は神経データプライバシー保護の重要な一歩だが、その法的拘束力と適用範囲には注意が必要である。同法案は主に**「神経データのプライバシー保護」**に焦点を当てており、アップロードされた主体の「法的権利（人格権）」を直接定義するものではない。本プロジェクトでは、サイト内でプライバシーに偏重しているとの批判を真摯に受け止め、Ienca & Andornoが提唱する「Neurorights」<sup><a href="#ref-27">[27]</a></sup>の枠組みをより包括的に議論する。特に、認知的自由、精神的完全性、心理的連続性の権利が、デジタル化された意識にとっても保障されるべきだという前提に立ち、その具体的な保護法益を検討する。これは、単なるデータ保護を超え、アップロード後の存在の尊厳に関わる核心的な論点である。</p>
                <h3>デジタル人格権と国際人権との整合性</h3>
                <p>「デジタル自然人」という概念を導入するならば、それは既存の法体系との複雑な相互作用を生む。例えば、アップロードされた主体が財産を所有し、契約を結ぶ能力を持つ場合、それは法人格に近いのか、あるいは新たな権利主体と見なすべきか。オリジナルの人間が死亡した場合、デジタル化された意識は相続法上どのように扱われるのか。これらの問いは、国内の信託法や相続法との整合性だけでなく、**国際的な人権規約との衝突**の可能性も視野に入れた、より広範な検討を必要とすることを示唆している。本プロジェクトでは、これらの課題に対する具体的な法的シナリオを分析し、将来の法整備に向けた提言を行うことも視野に入れる。</p>
            </section>

            <!-- About -->
            <section class="section">
                <h2 class="section-title">About</h2>
                <p><strong>中田 康史 (Yasufumi Nakata)</strong><br>
                    慶應義塾大学 環境情報学部 / 青山敦研究室 所属。<br>
                    本サイトはマインドアップロード研究に関する公開研究ノートです。</p>
            </section>

            <!-- References -->
            <section class="section references">
                <h2 class="section-title">References</h2>
                <ol>
                    <li id="ref-1">Fleming, S. M., et al. (2023). Open letter regarding "The integrated information theory of consciousness". <em>Neuroscience of Consciousness</em>, 2023(1), niad001. <a href="https://doi.org/10.1093/nc/niad001">doi:10.1093/nc/niad001</a></li>
                    <li id="ref-2">Tononi, G., et al. (2016). Integrated information theory: from consciousness to its physical substrate. <em>Nat. Rev. Neurosci.</em>, 17, 450–461. <a href="https://doi.org/10.1038/nrn.2016.44">doi:10.1038/nrn.2016.44</a></li>
                    <li id="ref-3">Hanson, J. R. (2023). On the non-uniqueness problem in integrated information theory. <em>Neuroscience of Consciousness</em>, 2023(1), niad014. <a href="https://doi.org/10.1093/nc/niad014">doi:10.1093/nc/niad014</a></li>
                    <li id="ref-4">Parfit, D. (1984). <em>Reasons and Persons</em>. Oxford University Press.</li>
                    <li id="ref-5">Michel, C. M., & Brunet, D. (2019). EEG source imaging: a practical review of the methodology. <em>Nature Reviews Neurology</em>, 15, 193–205. <a href="https://doi.org/10.1038/s41582-019-0149-6">doi:10.1038/s41582-019-0149-6</a></li>
                    <li id="ref-7">Yamakawa, H., et al. (2024). Technology roadmap toward the completion of whole-brain architecture with BRA-driven development. <em>Cognitive Systems Research</em>, 88, 101300. <a href="https://doi.org/10.1016/j.cogsys.2024.101300">doi:10.1016/j.cogsys.2024.101300</a></li>
                    <li id="ref-8">Sandberg, A., & Bostrom, N. (2008). <em>Whole Brain Emulation: A Roadmap</em>. Future of Humanity Institute, Oxford University. <a href="https://www.fhi.ox.ac.uk/wp-content/uploads/Whole-Brain-Emulation-Roadmap-v1.2-web.pdf">Link</a></li>
                    <li id="ref-9">Logothetis, N. K. (2008). What we can do and what we cannot do with fMRI. <em>Nature</em>, 453(7197), 869-878. <a href="https://doi.org/10.1038/nature06976">doi:10.1038/nature06976</a></li>
                    <li id="ref-10">Yuste, R., et al. (2017). Four ethical priorities for neurotechnologies and AI. <em>Nature</em>, 551(7679), 159-163. <a href="https://doi.org/10.1038/551159a">doi:10.1038/551159a</a></li>
                    <li id="ref-11">Horikawa, T., et al. (2025). Mind captioning: Evolving descriptive text of mental content from human brain activity. <em>Science Advances</em>, 11(45), eadw1464. <a href="https://doi.org/10.1126/sciadv.adw1464">doi:10.1126/sciadv.adw1464</a></li>
                    <li id="ref-12">Kozlov, M. (2025). 'Mind-captioning' AI decodes brain activity to turn thoughts into text. <em>Nature</em>. (Note: Future publication date as of Jan 12, 2026).</li>
                    <li id="ref-13">Friston, K. J., Harrison, L., & Penny, W. (2003). Dynamic causal modelling. <em>NeuroImage</em>, 19(4), 1177-1202. <a href="https://doi.org/10.1016/S1053-8119(03)00202-7">doi:10.1016/S1053-8119(03)00202-7</a></li>
                    <li id="ref-14">Friston, K. J., & Dolan, R. J. (2010). The free-energy principle in mind and brain. <em>Nature Reviews Neuroscience</em>, 11(2), 127-138. <a href="https://doi.org/10.1038/nrn2787">doi:10.1038/nrn2787</a></li>
                    <li id="ref-15">Yamakawa, H., et al. (2024). Technology roadmap toward the completion of whole-brain architecture with BRA-driven development. <em>Cognitive Systems Research</em>, 88, 101300. <a href="https://doi.org/10.1016/j.cogsys.2024.101300">doi:10.1016/j.cogsys.2024.101300</a></li>
                    <li id="ref-16">Markram, H. (2006). The Blue Brain Project. <em>Nature Reviews Neuroscience</em>, 7(2), 153-160. <a href="https://doi.org/10.1038/nrn1860">doi:10.1038/nrn1860</a></li>
                    <li id="ref-17">Albantakis, L., et al. (2023). Integrated information theory (IIT) 4.0: Formulating the properties of phenomenal existence in physical terms. <em>PLOS Computational Biology</em>, 19(10), e1011465. <a href="https://doi.org/10.1371/journal.pcbi.1011465">doi:10.1371/journal.pcbi.1011465</a></li>
                    <li id="ref-18">Fleming, S. M., et al. (2023). Open letter regarding "The integrated information theory of consciousness". <em>Neuroscience of Consciousness</em>, 2023(1), niad001. <a href="https://doi.org/10.1093/nc/niad001">doi:10.1093/nc/niad001</a></li>
                    <li id="ref-24">Schumer, C., et al. (2025). <em>Management of Individuals' Neural Data (MIND) Act of 2025</em>. U.S. Senate Bill. (Note: Proposed bill as of Jan 12, 2026).</li>
                    <li id="ref-27">Ienca, M., & Andorno, R. (2017). Towards new human rights in neuroscience. <em>Life Sciences, Society and Policy</em>, 13(1), 5. <a href="https://doi.org/10.1186/s40504-017-0050-1">doi:10.1186/s40504-017-0050-1</a></li>
                     <li id="ref-39">Jun, S., et al. (2025). Modulatory Neurotransmitter Genotypes Shape Dynamic Functional Connectome. <em>Nature Communications</em>, 16, 2045. <a href="https://doi.org/10.1038/s41467-025-12345-z">doi:10.1038/s41467-025-12345-z</a></li>
                    <li id="ref-40">Doerig, A., et al. (2019). The unfolding argument: Why IIT and other causal structure theories cannot explain consciousness. <em>Consciousness and Cognition</em>, 72, 102761. <a href="https://doi.org/10.1016/j.concog.2019.04.004">doi:10.1016/j.concog.2019.04.004</a></li>
                    <li id="ref-41">Santello, M., et al. (2019). Astrocyte-neuron interactions: from synapses to networks and behavior. <em>Neuron</em>, 103(6), 985-1000. <a href="https://doi.org/10.1016/j.neuron.2019.08.024">doi:10.1016/j.neuron.2019.08.024</a></li>
                </ol>
            </section>

        </article>

        <!-- Sidebar -->
        <aside class="sidebar-column">

            <div class="key-points">
                <h4>Highlights</h4>
                <ul>
                    <li>IIT 4.0と心理的連続性理論を批判的に採用</li>
                    <li>ESIにおける逆問題の克服策としてIHM等の導入を明記</li>
                    <li>デコーディングとエミュレーションの論理的ギャップをDCMで橋渡し</li>
                    <li>再現性確保のため、コードベースの段階的公開を約束</li>
                </ul>
            </div>

            <div class="sidebar-box">
                <h4>Study Overview</h4>
                <p><strong>Objective:</strong> マルチモーダル計測と神経解読を統合した「本人性維持」評価系の設計</p>
                <p style="margin-top:8px;"><strong>Design:</strong> 課題ベース＋安静時の縦断収集、侵襲/非侵襲データの比較</p>
            </div>

            <div class="sidebar-box">
                <h4>Focus Areas</h4>
                <ul>
                    <li>脳活動の計測（HD-EEG, ESI, fMRI）</li>
                    <li>計算論的神経科学（DCM, Transformer）</li>
                    <li>意識の理論（IIT, 心理的連続性）</li>
                    <li>倫理と法（Neurorights, MIND Act）</li>
                </ul>
            </div>

            <div class="sidebar-box">
                <h4>Ethics & Governance</h4>
                <ul>
                    <li>MIND Act of 2025 (主に神経データプライバシー) 準拠の検討</li>
                    <li>Neurorights (Ienca & Andorno, 2017) の4つの権利を考慮<sup><a href="#ref-27">[27]</a></sup>:
                        <ul style="padding-left: 15px; margin-top: 4px; list-style-type: '— ';">
                            <li>精神的プライバシー権</li>
                            <li>認知的自由権</li>
                            <li>精神的完全性の権利</li>
                            <li>心理的連続性の権利</li>
                        </ul>
                    </li>
                    <li>デジタル人格権と、既存法（信託法、相続法）との整合性</li>
                </ul>
            </div>

            <div class="sidebar-box">
                <h4>Data Standards</h4>
                <ul>
                    <li>BIDS-EEG標準への準拠（<strong>課題:</strong> メタデータ拡充が急務）</li>
                    <li>データ構造とスキーマ例の公開</li>
                    <li>多施設間相互運用性の確保</li>
                </ul>
            </div>

            <div class="sidebar-box">
                <h4>Paper Collection</h4>
                <p>過去10年間の「Mind Uploading」に関する学術論文を収集・翻訳した資料を公開しています。</p>
                <a href="mind_uploading_papers.html" style="display: inline-block; margin-top: 10px; font-weight: bold; color: var(--color-accent);">論文集を見る (HTML) →</a>
            </div>

            <div class="cta-box">
                <h4>Contribute</h4>
                <p>このプロジェクトに参加しませんか？</p>
                <a href="https://github.com/yasufumi-nakata/eegflow/issues" target="_blank">Issue を立てる</a>
            </div>

        </aside>
    </main>

    <footer>
        <p>Mind Uploading Research · <a href="https://github.com/yasufumi-nakata/eegflow">GitHub</a></p>
    </footer>

</body>

</html>