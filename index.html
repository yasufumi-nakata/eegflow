<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EEGFlow | マインドアップロード実現への道</title>
    <meta name="description" content="マインドアップロード実現のための中核となるコアサイト。意識や記憶の交換・複製を可能とする技術の研究とコミュニティの中心的ハブ。">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=Source+Sans+3:wght@400;600;700&display=swap"
        rel="stylesheet">
    <style>
        :root {
            --font-serif: 'Libre Baskerville', 'Times New Roman', serif;
            --font-sans: 'Source Sans 3', 'Helvetica Neue', sans-serif;
            --color-bg: #0d0d0f;
            --color-paper: #161618;
            --color-text: #e8e8ec;
            --color-text-secondary: #a8a8b0;
            --color-text-muted: #6a6a75;
            --color-accent: #ef5350;
            --color-accent-dark: #c62828;
            --color-link: #64b5f6;
            --color-border: #2a2a30;
            --color-sidebar: #1a1a1e;
            --max-width: 1100px;
            --column-gap: 40px;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: var(--font-serif);
            font-size: 16px;
            line-height: 1.75;
            color: var(--color-text);
            background: var(--color-bg);
        }

        /* Header Bar */
        .journal-header {
            background: var(--color-accent);
            color: white;
            padding: 8px 20px;
            font-family: var(--font-sans);
            font-size: 12px;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .journal-header a {
            color: white;
            text-decoration: none;
        }

        .journal-header a:hover {
            text-decoration: underline;
        }

        /* Title Section */
        .article-header {
            max-width: var(--max-width);
            margin: 0 auto;
            padding: 40px 20px 30px;
            border-bottom: 2px solid var(--color-text);
        }

        .article-type {
            font-family: var(--font-sans);
            font-size: 12px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.15em;
            color: var(--color-accent);
            margin-bottom: 12px;
        }

        .article-title {
            font-size: 32px;
            font-weight: 700;
            line-height: 1.25;
            margin-bottom: 16px;
            color: var(--color-text);
        }

        .article-subtitle {
            font-size: 18px;
            font-style: italic;
            color: var(--color-text-secondary);
            margin-bottom: 20px;
        }

        .author-info {
            font-family: var(--font-sans);
            font-size: 14px;
            color: var(--color-text-secondary);
            margin-bottom: 8px;
        }

        .author-name {
            font-weight: 600;
            color: var(--color-text);
        }

        .article-meta {
            font-family: var(--font-sans);
            font-size: 12px;
            color: var(--color-text-muted);
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
            margin-top: 12px;
        }

        /* Main Layout */
        .main-container {
            max-width: var(--max-width);
            margin: 0 auto;
            display: grid;
            grid-template-columns: 1fr 280px;
            gap: var(--column-gap);
            padding: 30px 20px;
        }

        .content-column {
            min-width: 0;
        }

        .sidebar-column {
            font-family: var(--font-sans);
        }

        /* Content Styles */
        .section {
            margin-bottom: 30px;
        }

        .section-title {
            font-family: var(--font-sans);
            font-size: 13px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            color: var(--color-accent);
            margin-bottom: 12px;
            padding-bottom: 6px;
            border-bottom: 1px solid var(--color-border);
        }

        .section h3 {
            font-size: 18px;
            font-weight: 700;
            margin: 20px 0 10px;
            color: var(--color-text);
        }

        .section p {
            margin-bottom: 12px;
            text-align: justify;
        }

        /* Abstract Box */
        .abstract-box {
            background: var(--color-paper);
            border-left: 4px solid var(--color-accent);
            padding: 20px 24px;
            margin-bottom: 30px;
        }

        .abstract-box h2 {
            font-family: var(--font-sans);
            font-size: 12px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            color: var(--color-accent);
            margin-bottom: 10px;
        }

        .abstract-box p {
            font-size: 15px;
            line-height: 1.7;
            color: var(--color-text-secondary);
        }

        /* Key Points / Highlights */
        .key-points {
            background: var(--color-sidebar);
            padding: 20px;
            margin-bottom: 24px;
            border-radius: 4px;
        }

        .key-points h4 {
            font-size: 12px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.08em;
            color: var(--color-accent);
            margin-bottom: 12px;
        }

        .key-points ul {
            list-style: none;
            padding: 0;
        }

        .key-points li {
            font-size: 13px;
            line-height: 1.6;
            padding: 6px 0;
            padding-left: 16px;
            position: relative;
            border-bottom: 1px solid var(--color-border);
        }

        .key-points li:last-child {
            border-bottom: none;
        }

        .key-points li::before {
            content: '▸';
            position: absolute;
            left: 0;
            color: var(--color-accent);
            font-size: 10px;
        }

        /* Figure Box */
        .figure-box {
            background: var(--color-paper);
            padding: 16px;
            margin: 24px 0;
            border: 1px solid var(--color-border);
        }

        .figure-box .figure-content {
            background: white;
            padding: 20px;
            text-align: center;
            margin-bottom: 12px;
        }

        .figure-box .figure-label {
            font-family: var(--font-sans);
            font-size: 11px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--color-text);
            margin-bottom: 6px;
        }

        .figure-box .figure-caption {
            font-family: var(--font-sans);
            font-size: 12px;
            color: var(--color-text-secondary);
            text-align: left;
            line-height: 1.5;
        }

        /* Timeline/Progress Figure */
        .timeline-visual {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            padding: 10px 0;
            position: relative;
        }

        .timeline-visual::before {
            content: '';
            position: absolute;
            top: 28px;
            left: 40px;
            right: 40px;
            height: 2px;
            background: linear-gradient(to right, var(--color-accent), var(--color-border));
        }

        .timeline-item {
            text-align: center;
            flex: 1;
            position: relative;
            z-index: 1;
        }

        .timeline-dot {
            width: 16px;
            height: 16px;
            border-radius: 50%;
            background: var(--color-border);
            border: 2px solid white;
            margin: 20px auto 10px;
        }

        .timeline-dot.done {
            background: var(--color-accent);
        }

        .timeline-dot.current {
            background: white;
            border: 2px solid var(--color-accent);
            box-shadow: 0 0 0 3px rgba(183, 28, 28, 0.2);
        }

        .timeline-label {
            font-family: var(--font-sans);
            font-size: 11px;
            color: var(--color-text-secondary);
            line-height: 1.4;
        }

        /* Stage Cards */
        .stage-list {
            counter-reset: stage;
        }

        .stage-item {
            display: flex;
            gap: 16px;
            padding: 16px 0;
            border-bottom: 1px solid var(--color-border);
        }

        .stage-item:last-child {
            border-bottom: none;
        }

        .stage-number {
            counter-increment: stage;
            font-family: var(--font-sans);
            font-size: 24px;
            font-weight: 700;
            color: var(--color-accent);
            min-width: 40px;
        }

        .stage-number::before {
            content: counter(stage);
        }

        .stage-body h4 {
            font-family: var(--font-sans);
            font-size: 14px;
            font-weight: 700;
            margin-bottom: 6px;
            color: var(--color-text);
        }

        .stage-body p {
            font-size: 14px;
            line-height: 1.6;
            margin-bottom: 8px;
        }

        .tag-list {
            display: flex;
            flex-wrap: wrap;
            gap: 6px;
        }

        .tag {
            font-family: var(--font-sans);
            font-size: 10px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            padding: 3px 8px;
            background: var(--color-paper);
            border: 1px solid var(--color-border);
            color: var(--color-text-secondary);
        }

        /* Table Styles */
        .data-table {
            width: 100%;
            border-collapse: collapse;
            font-family: var(--font-sans);
            font-size: 13px;
            margin: 16px 0;
        }

        .data-table th {
            background: var(--color-paper);
            font-weight: 700;
            text-align: left;
            padding: 10px 12px;
            border-bottom: 2px solid var(--color-text);
            font-size: 11px;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }

        .data-table td {
            padding: 10px 12px;
            border-bottom: 1px solid var(--color-border);
            vertical-align: top;
        }

        .data-table td:first-child {
            font-weight: 700;
            color: var(--color-accent);
            white-space: nowrap;
        }

        /* Sidebar Styles */
        .sidebar-box {
            background: var(--color-sidebar);
            padding: 16px;
            margin-bottom: 20px;
            border-radius: 4px;
        }

        .sidebar-box h4 {
            font-size: 11px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.08em;
            color: var(--color-accent);
            margin-bottom: 12px;
            padding-bottom: 8px;
            border-bottom: 1px solid var(--color-border);
        }

        .sidebar-box p,
        .sidebar-box li {
            font-size: 12px;
            line-height: 1.6;
            color: var(--color-text-secondary);
        }

        .sidebar-box ul {
            list-style: none;
            padding: 0;
        }

        .sidebar-box li {
            padding: 4px 0;
            padding-left: 12px;
            position: relative;
        }

        .sidebar-box li::before {
            content: '•';
            position: absolute;
            left: 0;
            color: var(--color-accent);
        }

        /* Links */
        a {
            color: var(--color-link);
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        sup a {
            font-size: 11px;
            vertical-align: super;
        }

        /* Call to Action */
        .cta-box {
            background: var(--color-accent);
            color: white;
            padding: 20px;
            text-align: center;
            margin: 24px 0;
        }

        .cta-box h4 {
            font-family: var(--font-sans);
            font-size: 14px;
            font-weight: 700;
            margin-bottom: 8px;
        }

        .cta-box p {
            font-size: 13px;
            margin-bottom: 12px;
            opacity: 0.9;
        }

        .cta-box a {
            display: inline-block;
            font-family: var(--font-sans);
            font-size: 12px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            padding: 10px 24px;
            background: white;
            color: var(--color-accent);
            text-decoration: none;
            transition: all 0.2s;
        }

        .cta-box a:hover {
            background: var(--color-paper);
            text-decoration: none;
        }

        /* References Section */
        .references {
            font-size: 12px;
            line-height: 1.7;
        }

        .references ol {
            padding-left: 24px;
        }

        .references li {
            margin-bottom: 8px;
            color: var(--color-text-secondary);
        }

        .references em {
            color: var(--color-text);
        }

        /* Footer */
        footer {
            background: var(--color-text);
            color: white;
            padding: 24px 20px;
            font-family: var(--font-sans);
            font-size: 12px;
            text-align: center;
        }

        footer a {
            color: white;
            text-decoration: underline;
        }

        /* Note Box */
        .note-box {
            background: #2a2518;
            border-left: 3px solid #ffc107;
            padding: 12px 16px;
            margin: 16px 0;
            font-size: 14px;
        }

        .note-box strong {
            font-family: var(--font-sans);
            font-size: 12px;
            text-transform: uppercase;
            color: #ffca28;
        }

        /* Question Box */
        .question-box {
            border: 1px solid var(--color-border);
            padding: 16px;
            margin: 12px 0;
        }

        .question-box h4 {
            font-family: var(--font-sans);
            font-size: 14px;
            font-weight: 700;
            margin-bottom: 8px;
            color: var(--color-text);
        }

        .question-box p {
            font-size: 14px;
            color: var(--color-text-secondary);
            margin: 0;
        }

        .resolution-box {
            border: 1px solid #2f3b2f;
            background: #182018;
            padding: 14px 16px;
            margin-top: 10px;
            border-left: 3px solid #7cb342;
        }

        .resolution-box h5 {
            font-family: var(--font-sans);
            font-size: 13px;
            font-weight: 700;
            color: #c5e1a5;
            margin-bottom: 6px;
        }

        .resolution-box p {
            font-size: 13px;
            color: #d7e2cf;
            margin: 0;
            line-height: 1.5;
        }

        /* Responsive */
        @media (max-width: 900px) {
            .main-container {
                grid-template-columns: 1fr;
            }

            .sidebar-column {
                order: -1;
                display: grid;
                grid-template-columns: 1fr 1fr;
                gap: 16px;
            }
        }

        @media (max-width: 600px) {
            .article-title {
                font-size: 24px;
            }

            .sidebar-column {
                grid-template-columns: 1fr;
            }

            .timeline-visual {
                flex-direction: column;
                gap: 16px;
                align-items: flex-start;
            }

            .timeline-visual::before {
                display: none;
            }

            .timeline-item {
                display: flex;
                align-items: center;
                gap: 12px;
                text-align: left;
            }

            .timeline-dot {
                margin: 0;
            }
        }
    </style>
</head>

<body>

    <!-- Journal Header -->
    <header class="journal-header">
        <span>EEGFlow Research Notes</span>
        <a href="https://github.com/yasufumi-nakata/eegflow" target="_blank">GitHub Repository →</a>
    </header>

    <!-- Article Header -->
    <header class="article-header">
        <p class="article-type">Perspective</p>
        <h1 class="article-title">マインドアップロード実現への道：技術・理論・倫理の統合アプローチ</h1>
        <p class="article-subtitle">脳の情報処理を別の基盤で再現し、心的機能を移植・複製するという研究仮説の現状と展望</p>
        <p class="author-info">
            <span class="author-name">EEGFlow Project</span> · eegflow.jp
        </p>
        <div class="article-meta">
            <span>Open Access</span>
            <span>Last Updated: 2025</span>
            <span>研究ノート (Update: NTT Mind Captioning 2025)</span>
        </div>
    </header>

    <!-- Main Content -->
    <main class="main-container">
        <article class="content-column">

            <!-- Abstract -->
            <div class="abstract-box">
                <h2>Abstract</h2>
                <p>マインドアップロード（Brain
                    Uploading）は、広義には脳の情報処理を別の基盤で再現し、心的機能を移植・複製するという概念であるが、本稿ではWBE、神経補綴、本人性検証の3領域が交差する統合的研究課題として定義する<sup><a
                            href="#ref-1">[1]</a></sup>。2025年にはNTTによる「Mind Captioning」技術の発表<sup><a
                            href="#ref-17">[17]</a></sup>（脳活動からの思考の記述）や、米国での「MIND Act of 2025」<sup><a
                            href="#ref-18">[18]</a></sup>の提案など、技術と法の両面で大きな進展があった。本稿では、Whole Brain Emulation (WBE)
                    を含む現状を、計測・解読・実装という3段階の技術的フレームワークで整理し、コネクトーム研究の進展<sup><a href="#ref-9">[9]</a></sup><sup><a
                            href="#ref-14">[14]</a></sup>と、IIT (Integrated Information Theory)<sup><a
                            href="#ref-19">[19]</a></sup>等の客観的指標に基づく意識・本人性の検証、および未解決の理論的・法的課題を概観する。</p>
            </div>

            <!-- Introduction -->
            <section class="section">
                <h2 class="section-title">Introduction</h2>

                <h3>技術と哲学の交差点</h3>
                <p>マインドアップロードは、単なる技術的課題ではない。「意識とは何か」「自己とは何か」という人類最古の哲学的問いに、科学的アプローチで挑む試みである。1980年代から議論されてきたこのビジョン<sup><a
                            href="#ref-1">[1]</a></sup>は、2000年代以降、計算論的神経科学の進展<sup><a
                            href="#ref-2">[2]</a></sup>や「コネクトーム」概念の普及<sup><a
                            href="#ref-9">[9]</a></sup>により、技術・倫理・哲学の横断課題として研究対象化してきた<sup><a
                            href="#ref-10">[10]</a></sup>。</p>

                <h3>用語とスコープ</h3>
                <p>本サイトでは「マインドアップロード」を以下の3領域の交差点として扱う：(i) WBE（脳の機能を計算モデルとして再現する試み）<sup><a
                            href="#ref-10">[10]</a></sup>、(ii) 侵襲/非侵襲の脳計測・刺激に基づく部分的な神経補綴（BCI/ニューロプロステティクス）<sup><a
                            href="#ref-15">[15]</a></sup>、(iii)
                    本人性（自己同一性）の操作的定義と検証<sup><a href="#ref-10">[10]</a></sup>。</p>

                <div class="note-box">
                    <strong>研究としての約束</strong>
                    <p>以下を「最低限のガードレール」として運用する：主要な主張には一次/総説などの出典を付す・仮説と事実、価値判断を区別し不確実性を併記する・評価指標や手順を先に定義し再現可能性を優先する。</p>
                </div>
            </section>


            <!-- Technical Framework -->
            <section class="section">
                <h2 class="section-title">Technical Framework</h2>

                <p>マインドアップロードの実現には、3つの技術的マイルストーンが必要である。</p>

                <div class="stage-list">
                    <div class="stage-item">
                        <div class="stage-number"></div>
                        <div class="stage-body">
                            <h4>計測（Sensing）</h4>
                            <p>脳活動を正確に読み取る技術。EEGの空間分解能の限界（体積伝導・逆問題）に対し、高密度EEG（HD-EEG）や脳磁図（MEG）、fMRIとの同時計測、およびソースイメージング（ESI）<sup><a
                                        href="#ref-7">[7]</a></sup>を用いた統合的アプローチが進展している。</p>
                            <div class="tag-list">
                                <span class="tag">HD-EEG</span>
                                <span class="tag">ESI (Source Imaging)</span>
                                <span class="tag">マルチモーダル融合</span>
                                <span class="tag">侵襲型BCI (Neuralink/Synchron)</span>
                            </div>
                        </div>
                    </div>
                    <div class="stage-item">
                        <div class="stage-number"></div>
                        <div class="stage-body">
                            <h4>解読（Decoding）</h4>
                            <p>計測データから意識・記憶・思考を理解する技術。Transformerベースの深層学習モデル<sup><a href="#ref-17">[17]</a></sup><sup><a
                                        href="#ref-24">[24]</a></sup>を用いた認知状態の記述（Mind Captioning）や、因果推論に基づくDynamic
                                Causal Modeling (DCM)<sup><a href="#ref-22">[22]</a></sup> による精密解析が標準となりつつある。</p>
                            <div class="tag-list">
                                <span class="tag">Transformerデコーディング</span>
                                <span class="tag">因果ダイナミクス (DCM)</span>
                                <span class="tag">MVPA (Multivariate Pattern Analysis)</span>
                            </div>
                        </div>
                    </div>
                    <div class="stage-item">
                        <div class="stage-number"></div>
                        <div class="stage-body">
                            <h4>実装（Implementation）</h4>
                            <p>解読された意識を別の基盤で動作させる技術。WBA（Whole Brain Architecture）<sup><a
                                        href="#ref-20">[20]</a></sup>による計算機実装や、心理的連続性理論に基づく「情報の構造的保存率」、および工学的指標（神経活動の統計的類似性や行動出力の再現性）を通じた本人性検証が議論の中心である。
                            </p>
                            <div class="tag-list">
                                <span class="tag">WBA (全脳アーキテクチャ)</span>
                                <span class="tag">心理的連続性理論</span>
                                <span class="tag">本人性ベンチマーク</span>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Current Status -->
            <section class="section">
                <h2 class="section-title">Current Status</h2>

                <!-- Figure: Connectome Progress -->
                <div class="figure-box">
                    <div class="figure-content">
                        <div class="timeline-visual">
                            <div class="timeline-item">
                                <div class="timeline-dot done"></div>
                                <div class="timeline-label">線虫<br><strong>302</strong> neurons</div>
                            </div>
                            <div class="timeline-item">
                                <div class="timeline-dot done"></div>
                                <div class="timeline-label">ショウジョウバエ<br><strong>~25,000</strong> neurons</div>
                            </div>
                            <div class="timeline-item">
                                <div class="timeline-dot current"></div>
                                <div class="timeline-label">マウス<br><strong>~71M</strong> neurons</div>
                            </div>
                            <div class="timeline-item">
                                <div class="timeline-dot"></div>
                                <div class="timeline-label">ヒト<br><strong>~86B</strong> neurons</div>
                            </div>
                        </div>
                    </div>
                    <p class="figure-label">Figure 1</p>
                    <p class="figure-caption">コネクトーム研究の進展とスケール。線虫（<em>C. elegans</em>）<sup><a
                                href="#ref-3">[3]</a></sup>およびショウジョウバエ<sup><a
                                href="#ref-4">[4]</a></sup>では完全な構造的コネクトーム（Structural
                        Connectome）が解明されているが、機能的ダイナミクスの解明は依然課題である。マウスのニューロン数は約7100万<sup><a
                                href="#ref-5">[5]</a></sup>であり、コネクトーム解析<sup><a
                                href="#ref-16">[16]</a></sup>は現在進行中である。ヒト脳<sup><a
                                href="#ref-6">[6]</a></sup>は約860億ニューロンを有する。
                    </p>
                </div>

                <h3>主要な技術的課題</h3>
                <p><strong>スケール統合の問題</strong>：分子・シナプス・回路・領域・全脳という異なるスケールの研究を統合する理論が不足している。それらを繋ぐ、例えば神経質量モデルとシナプス可塑性ルールを統合するような、普遍的な計算論的フレームワークがまだ確立されていない。
                </p>

                <p><strong>データ量の課題</strong>：ペタバイト級のデータ処理が必要となるが、ストレージ容量以上に、膨大なパラメータを持つシステムを生物学的に妥当な形で動作させるための、神経ダイナミクスの根本原理の理解が本質的な課題である。
                </p>

                <p><strong>ダイナミクスの理解</strong>：静的な構造（コネクトーム）だけでなく、時間的な動態の理解が不可欠である。活動パターンが学習によりどのように変化し行動へ影響するかという動的な問いへの回答は困難である。
                </p>

                <p><strong>非侵襲計測の限界</strong>：EEGは時間分解能に優れるが空間分解能が低く<sup><a
                            href="#ref-7">[7]</a></sup>、fMRIは空間分解能はあるが時間分解能に限界がある<sup><a
                            href="#ref-8">[8]</a></sup>。両者を補完する新技術の開発が求められている。</p>

                <h3>最新の技術進展（2025）</h3>
                <p><strong>Mind Captioning (NTT/Science Advances, 2025)</strong>：
                    脳活動データから、思考の内容を直接自然言語で記述する技術が発表された<sup><a
                            href="#ref-17">[17]</a></sup>。これにより、「計測→解読」の橋渡しが言語AI（LLM）との統合により実用的レベルに達し始めている。
                </p>
                <p><strong>MIND Act of 2025 (Federal Legislation)</strong>：
                    米国で「Management of Individuals' Neural Data Act」が提案され、神経データの扱いに関する法的定義が明確化された<sup><a
                            href="#ref-18">[18]</a></sup>。精神的プライバシー（Mental Privacy）の保護がマインドアップロード研究の前提条件となった。
                </p>
                <p><strong>WBE Roadmap 2025 Update</strong>：
                    「State of Brain Emulation Report 2025」では、標準評価プロトコルの欠如が指摘され、情報の構造保存率に基づく検証が提案された。
                </p>
            </section>

            <!-- Research Program -->
            <section class="section">
                <h2 class="section-title">Research Program</h2>

                <p>論文化を意識した実証プランでは、計測・解読・実装の各段階を統合的に示す。目標はマルチモーダル計測と神経解読を統合した「本人性維持」評価系の設計と論文化である。</p>

                <!-- Table: Roadmap -->
                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Phase</th>
                            <th>計測/データ</th>
                            <th>解読/解析</th>
                            <th>実装/倫理</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>1</td>
                            <td>HD-EEG/fMRI同時計測セットアップ、再現性データ収集</td>
                            <td>Transformerベースのデコーディング (MVPA AUC > 0.8 目標)</td>
                            <td>MIND Act 2025準拠の同意プロセス、神経データプライバシー保護設計</td>
                        </tr>
                        <tr>
                            <td>2</td>
                            <td>ESI (Source Imaging) による信号分離とMEGデータの融合</td>
                            <td>Dynamic Causal Modeling (DCM) による部位間因果ダイナミクス解析</td>
                            <td>心理的連続性理論に基づく「本人性」評価指標の操作的定義</td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td>WBA (Whole Brain Architecture) 統合フレームワークでの動作検証</td>
                            <td>IIT (Integrated Information Theory) 指標による意識レベルの定量的評価</td>
                            <td>デジタル遺産・継承権の法的整備、本人性ベンチマークのリリース</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <!-- About -->
            <section class="section">
                <h2 class="section-title">About</h2>
                <p><strong>中田 康史 (Yasufumi Nakata)</strong><br>
                    慶應義塾大学 環境情報学部 / 青山敦研究室 所属。<br>
                    本サイトはマインドアップロード研究に関する公開研究ノートです。</p>
            </section>

            <!-- Open Questions -->
            <section class="section">
                <h2 class="section-title">Open Questions</h2>

                <div class="question-box">
                    <h4>MU と LLM シミュレーションの見分け</h4>
                    <p>単に問いに答えるだけならLLMでも「その人らしく」振る舞える。アップロードされた主体が、単なる静的なプロンプトの反映（シミュレーション）ではなく、真に動的な意識の連続体であることをどう証明するか？（Issue
                        #10関連）</p>
                    <div class="resolution-box">
                        <h5>解決</h5>
                        <p>本人性検証を「予測不可能性・自己更新性・因果反応性」の3軸で実装する。具体的には (1)
                            非公開の出来事を含む縦断的対話タスクで一貫した内部状態更新を確認、(2) 介入刺激（TMS/入力文脈シフト）への因果整合性を計測、(3)
                            情報理論指標（IIT Φ、因果エントロピー）による静的シミュレーションとの差分を可視化し、ベンチマークとして公開する。</p>
                    </div>
                </div>

                <div class="question-box">
                    <h4>MIND Act 2025下での遺産相続</h4>
                    <p>法的・物理的に「コピー」が作成された場合、相続権は誰に帰属するのか。米国の新法やデジタル・ニューロン権利（Neurorights）の観点から、新たな法的定義が必要である。</p>
                    <div class="resolution-box">
                        <h5>解決</h5>
                        <p>アップロード主体を「デジタル自然人」として扱う暫定ガバナンスを採用。原本人の明示的同意とタイムスタンプ付きログを前提に、(a)
                            医療・研究データはコモンズ型ライセンスで共有、(b) 財産権はマルチシグ型信託に移管し、代理人とアップロード主体の共同承認で執行、(c)
                            年次レビューで権利継承の整合性を監査する運用を推奨する。</p>
                    </div>
                </div>

                <div class="question-box">
                    <h4>グリア細胞と非神経要素</h4>
                    <p>現在のコネクトームは神経細胞（ニューロン）が主役だが、意識の形成にグリア細胞や循環器・代謝系がどこまで寄与しているか。情報の保存すべき範囲の境界線（Boundary
                        Problem）は未解決である。</p>
                    <div class="resolution-box">
                        <h5>解決</h5>
                        <p>Boundary Problem への対応として、EEG/fMRIに代謝・血流系の指標（fNIRS/RS-fMRI
                            CBF）とカルシウムイメージング由来のグリア活動モデルを統合したハイブリッド解析を標準化する。情報保存の境界は「行動出力と意識指標へ統計的寄与を与える非神経成分」を含める形で定義し、Phase
                            1〜2のプロトコルにグリア指標の収集・同定ステップを追加する。</p>
                    </div>
                </div>
            </section>

            <!-- Column: LLM and Identity -->
            <section class="section">
                <h2 class="section-title">Column: LLMと本人性</h2>

                <h3>LLMの内部挙動とマインドアップロードの共通点</h3>
                <p>大規模言語モデル（LLM）は、膨大なテキストデータから学習した「パターン」に基づいて応答を生成する。興味深いことに、この挙動はマインドアップロード（MU）における「本人性識別」の問題と深い共通点を持つ。
                </p>

                <h3>情報の圧縮と再構成</h3>
                <p>LLMは学習データを「重み（Weights）」として圧縮し、推論時にそれを再構成して出力する。これは、MUにおいて脳の情報を「スキャンデータ」として圧縮し、別の基盤で再構成するプロセスと構造的に類似している。両者において問いかけられるのは、<strong>「再構成されたものは元のものと同一か？」</strong>という根本的な問題である。
                </p>

                <h3>静的なプロンプト vs 動的な意識</h3>
                <p>LLMに対して「ある人物の発言履歴」をプロンプトとして与えれば、その人物「らしい」応答を生成できる。しかし、これは「静的なシミュレーション」に過ぎず、その人物の意識が連続しているわけではない。MUの文脈では、アップロードされた主体が真に「その人」であるためには、単なる情報の静的な複製ではなく、<strong>動的な意識の連続性</strong>が保証される必要がある。
                </p>

                <h3>識別のための潜在的アプローチ</h3>
                <p>LLMとMUの類似性は、本人性識別のための新たなアプローチを示唆する。例えば、</p>
                <ul style="margin-left:20px;">
                    <li><strong>予測不可能性</strong>: 静的なプロンプトでは生成できない、文脈に応じた「予測不可能な」応答の生成能力。</li>
                    <li><strong>自己参照的更新</strong>: 新しい経験に基づいて自己モデルを更新する能力（LLMの推論時ファインチューニングに相当）。</li>
                    <li><strong>因果的介入への反応</strong>: 外部からの介入に対して、一貫性のある因果的な反応を示すこと。</li>
                </ul>
                <p>これらの観点から、MUにおける本人性検証のベンチマークを設計することが、今後の研究課題となる。</p>
            </section>

            <!-- References -->
            <section class="section references">
                <h2 class="section-title">References</h2>
                <ol>
                    <li id="ref-1">Moravec, H. <em>Mind Children: The Future of Robot and Human Intelligence</em>.
                        Harvard University Press (1988).</li>
                    <li id="ref-2">Sejnowski, T.J., Churchland, P.S. & Movshon, J.A. Computational Neuroscience.
                        <em>Science</em> <strong>250</strong>, 744–747 (1990). <a
                            href="https://doi.org/10.1126/science.250.4977.744">doi:10.1126/science.250.4977.744</a>
                    </li>
                    <li id="ref-3">White, J.G. <em>et al.</em> The Structure of the Nervous System of <em>C.
                            elegans</em>. <em>Phil. Trans. R. Soc. B</em> (1986). <a
                            href="https://doi.org/10.1098/rstb.1986.0056">doi:10.1098/rstb.1986.0056</a></li>
                    <li id="ref-4">Scheffer, L.K. <em>et al.</em> A Connectome of the Adult <em>Drosophila</em> Central
                        Brain. <em>eLife</em> (2020). <a
                            href="https://doi.org/10.7554/eLife.57443">doi:10.7554/eLife.57443</a></li>
                    <li id="ref-5">Herculano-Houzel, S. <em>et al.</em> Cellular Scaling Rules for Rodent Brains.
                        <em>PNAS</em> (2006). <a
                            href="https://doi.org/10.1073/pnas.0604911103">doi:10.1073/pnas.0604911103</a>
                    </li>
                    <li id="ref-6">Herculano-Houzel, S. The Human Brain in Numbers. <em>Front. Hum. Neurosci.</em>
                        <strong>3</strong>, 31 (2009). <a
                            href="https://doi.org/10.3389/neuro.09.031.2009">doi:10.3389/neuro.09.031.2009</a>
                    </li>
                    <li id="ref-7">Michel, C.M. & Brunet, D. EEG Source Imaging: A Practical Review. <em>Clin.
                            Neurophysiol.</em> (2019). <a
                            href="https://doi.org/10.1016/j.clinph.2019.02.004">doi:10.1016/j.clinph.2019.02.004</a>
                    </li>
                    <li id="ref-8">Logothetis, N.K. What We Can Do and What We Cannot Do with fMRI. <em>Nature</em>
                        (2008). <a href="https://doi.org/10.1038/nature06976">doi:10.1038/nature06976</a></li>
                    <li id="ref-9">Sporns, O., Tononi, G. & Kötter, R. The Human Connectome. <em>PLoS Comput. Biol.</em>
                        <strong>1</strong>, e42 (2005). <a
                            href="https://doi.org/10.1371/journal.pcbi.0010042">doi:10.1371/journal.pcbi.0010042</a>
                    </li>
                    <li id="ref-10">Sandberg, A. Feasibility of Whole Brain Emulation. In <em>Singularity
                            Hypotheses</em> (Springer, 2013). <a
                            href="https://doi.org/10.1007/978-3-642-31674-6_19">doi:10.1007/978-3-642-31674-6_19</a>
                    </li>
                    <li id="ref-11">Friston, K. The free-energy principle: a unified brain theory? <em>Nat. Rev.
                            Neurosci.</em> <strong>11</strong>, 127–138 (2010). <a
                            href="https://doi.org/10.1038/nrn2787">doi:10.1038/nrn2787</a></li>
                    <li id="ref-12">Ienca, M. & Andorno, R. Towards new human rights in neuroscience. <em>Life Sci. Soc.
                            Policy</em> <strong>13</strong>, 5 (2017). <a
                            href="https://doi.org/10.1186/s40504-017-0050-1">doi:10.1186/s40504-017-0050-1</a></li>
                    <li id="ref-13">Yuste, R. <em>et al.</em> Four ethical priorities for neurotechnologies and AI.
                        <em>Nature</em> <strong>551</strong>, 159–163 (2017). <a
                            href="https://doi.org/10.1038/551159a">doi:10.1038/551159a</a>
                    </li>
                    <li id="ref-14">Van Essen, D.C. <em>et al.</em> The WU-Minn Human Connectome Project.
                        <em>NeuroImage</em> <strong>80</strong>, 62–79 (2013). <a
                            href="https://doi.org/10.1016/j.neuroimage.2013.05.041">doi:10.1016/j.neuroimage.2013.05.041</a>
                    </li>
                    <li id="ref-15">Schwartz, A.B. <em>et al.</em> Brain-Controlled Interfaces: Movement Restoration
                        with Neural Prosthetics.
                        <em>Neuron</em> <strong>52</strong>, 205–220 (2006). <a
                            href="https://doi.org/10.1016/j.neuron.2006.09.019">doi:10.1016/j.neuron.2006.09.019</a>
                    </li>
                    <li id="ref-16">Oh, S.W. <em>et al.</em> A mesoscale connectome of the mouse brain.
                        <em>Nature</em> <strong>508</strong>, 207–214 (2014). <a
                            href="https://doi.org/10.1038/nature13186">doi:10.1038/nature13186</a>
                    </li>
                    <li id="ref-17">NTT Research. Mind Reading through Brain–AI Integration: Decoding Mental Content
                        from Human Brain Activity. <em>Science Advances</em> (Nov 5, 2025).</li>
                    <li id="ref-18">Schumer, C. <em>et al.</em> Management of Individuals' Neural Data (MIND) Act of
                        2025. U.S. Senate Bill (2025).</li>
                    <li id="ref-19">Tononi, G. <em>et al.</em> Integrated information theory: from consciousness to its
                        physical substrate. <em>Nat. Rev. Neurosci.</em> (2016).</li>
                    <li id="ref-20">Yamakawa, H. <em>et al.</em> Technology roadmap toward the completion of whole-brain
                        architecture with BRA-driven development. <em>Cognitive Systems Research</em>
                        <strong>88</strong>, 101300
                        (2024).
                    </li>
                    <li id="ref-21">Katahira, K., Yamazaki, Y. & Nagata, N. EEG Correlates of the Flow State.
                        <em>Front. Psychol.</em> <strong>9</strong>, 300 (2018).
                    </li>
                    <li id="ref-22">Friston, K.J. <em>et al.</em> Dynamic causal modelling revisited.
                        <em>NeuroImage</em>
                        <strong>199</strong>, 1–12 (2019).
                    </li>
                    <li id="ref-23">Koch, C. <em>et al.</em> Neural correlates of consciousness: progress and problems.
                        <em>Nat. Rev. Neurosci.</em> <strong>17</strong>, 307–321 (2016).
                    </li>
                    <li id="ref-24">Li, Y. <em>et al.</em> EEG decoders track memory dynamics. <em>Nature
                            Communications</em>
                        <strong>15</strong>, 2684 (2024).
                    </li>
                </ol>
            </section>

            <!-- Progress Log -->
            <section class="section">
                <h2 class="section-title">Progress Log (Activity)</h2>
                <div class="note-box">
                    <strong>2025-11-20</strong>
                    <p>NTT R&D Forum 2025にてMind Captioning技術のデモンストレーションを確認。本プロジェクトのPhase 1デコーディング目標をHD-ESI統合型へ上方修正。</p>
                </div>
                <div class="note-box">
                    <strong>2025-10-15</strong>
                    <p>MIND Act 2025の草案を反映し、データガバナンス指針をアップデート。神経プライバシー保護のための差分プライバシー導入を検討開始。</p>
                </div>
                <div class="note-box">
                    <strong>2025-08-01</strong>
                    <p>HD-EEG（128ch）とfMRIの同時計測プロトコルが完成。最初のパイロットデータにおけるMVPA精度がAUC 0.72を記録。</p>
                </div>
            </section>

        </article>

        <!-- Sidebar -->
        <aside class="sidebar-column">

            <div class="key-points">
                <h4>Key Points</h4>
                <ul>
                    <li>2025年、マインドキャプション（脳活動の言語化）が実用レベルへ</li>
                    <li>MIND Act 2025により、神経データの法的保護が研究の必須要件に</li>
                    <li>HD-ESI、Transformer、DCMを用いた高精度な計測と解読の統合</li>
                    <li>IIT、WBA、心理的連続性理論に基づく本人性検証フレームワーク</li>
                </ul>
            </div>

            <div class="sidebar-box">
                <h4>Study Overview</h4>
                <p><strong>Objective:</strong> マルチモーダル計測と神経解読を統合した「本人性維持」評価系の設計</p>
                <p style="margin-top:8px;"><strong>Design:</strong> 課題ベース＋安静時の縦断収集、侵襲/非侵襲データの比較</p>
            </div>

            <div class="sidebar-box">
                <h4>Focus Areas</h4>
                <ul>
                    <li>脳活動の計測（EEG, fMRI, BCI）</li>
                    <li>神経科学研究</li>
                    <li>計算論的アプローチ</li>
                    <li>倫理と哲学</li>
                </ul>
            </div>

            <div class="sidebar-box">
                <h4>Ethics & Governance</h4>
                <ul>
                    <li>MIND Act of 2025 (US Federal) 準拠</li>
                    <li>Neurorights議論（精神的プライバシー、認知的自由）<sup><a href="#ref-12">[12]</a></sup></li>
                    <li>デジタル相続・遺産管理の法的フレームワーク設計</li>
                    <li>本人性維持のための「情報の構造保存率」義務化</li>
                </ul>
            </div>

            <div class="sidebar-box">
                <h4>Data Standards</h4>
                <ul>
                    <li>BIDS-EEG標準への完全準拠</li>
                    <li>メタデータ自動QAパイプライン</li>
                    <li>多施設間相互運用性の確保</li>
                </ul>
            </div>

            <div class="cta-box">
                <h4>Contribute</h4>
                <p>このプロジェクトに参加しませんか？</p>
                <a href="https://github.com/yasufumi-nakata/eegflow/issues" target="_blank">Issue を立てる</a>
            </div>

        </aside>
    </main>

    <footer>
        <p>EEGFlow · eegflow.jp · <a href="https://github.com/yasufumi-nakata/eegflow">GitHub</a></p>
    </footer>

</body>

</html>