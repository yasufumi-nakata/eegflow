<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mind Uploading Research | マインドアップロード実現への道</title>
    <meta name="description" content="マインドアップロード実現のための中核となるコアサイト。意識や記憶の交換・複製を可能とする技術の研究とコミュニティの中心的ハブ。">
    <meta property="og:title" content="EEGFlow | マインドアップロード実現への道">
    <meta property="og:description" content="マインドアップロード実現のための中核となるコアサイト。意識や記憶の交換・複製を可能とする技術の研究とコミュニティの中心的ハブ。">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://eegflow.jp">
    <meta property="og:image" content="https://eegflow.jp/ogp.jpg">
    <meta name="twitter:card" content="summary_large_image">
    <link rel="icon"
        href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🧠</text></svg>">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=Source+Sans+3:wght@400;600;700&display=swap"
        rel="stylesheet">
    <style>
        :root {
            --font-serif: 'Libre Baskerville', 'Times New Roman', serif;
            --font-sans: 'Source Sans 3', 'Helvetica Neue', sans-serif;
            --color-bg: #0d0d0f;
            --color-paper: #161618;
            --color-text: #e8e8ec;
            --color-text-secondary: #a8a8b0;
            --color-text-muted: #6a6a75;
            --color-accent: #ef5350;
            --color-accent-dark: #c62828;
            --color-link: #64b5f6;
            --color-border: #2a2a30;
            --color-sidebar: #1a1a1e;
            --max-width: 1100px;
            --column-gap: 40px;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: var(--font-serif);
            font-size: 16px;
            line-height: 1.75;
            color: var(--color-text);
            background: var(--color-bg);
        }

        /* Header Bar */
        .journal-header {
            background: var(--color-accent);
            color: white;
            padding: 8px 20px;
            font-family: var(--font-sans);
            font-size: 12px;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .journal-header a {
            color: white;
            text-decoration: none;
        }

        .journal-header a:hover {
            text-decoration: underline;
        }

        /* Title Section */
        .article-header {
            max-width: var(--max-width);
            margin: 0 auto;
            padding: 40px 20px 30px;
            border-bottom: 2px solid var(--color-text);
        }

        .article-type {
            font-family: var(--font-sans);
            font-size: 12px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.15em;
            color: var(--color-accent);
            margin-bottom: 12px;
        }

        .article-title {
            font-size: 32px;
            font-weight: 700;
            line-height: 1.25;
            margin-bottom: 16px;
            color: var(--color-text);
        }

        .article-subtitle {
            font-size: 18px;
            font-style: italic;
            color: var(--color-text-secondary);
            margin-bottom: 20px;
        }

        .author-info {
            font-family: var(--font-sans);
            font-size: 14px;
            color: var(--color-text-secondary);
            margin-bottom: 8px;
        }

        .author-name {
            font-weight: 600;
            color: var(--color-text);
        }

        .article-meta {
            font-family: var(--font-sans);
            font-size: 12px;
            color: var(--color-text-muted);
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
            margin-top: 12px;
        }

        /* Main Layout */
        .main-container {
            max-width: var(--max-width);
            margin: 0 auto;
            display: grid;
            grid-template-columns: 1fr 280px;
            gap: var(--column-gap);
            padding: 30px 20px;
        }

        .content-column {
            min-width: 0;
        }

        .sidebar-column {
            font-family: var(--font-sans);
        }

        /* Content Styles */
        .section {
            margin-bottom: 30px;
        }

        .section-title {
            font-family: var(--font-sans);
            font-size: 13px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            color: var(--color-accent);
            margin-bottom: 12px;
            padding-bottom: 6px;
            border-bottom: 1px solid var(--color-border);
        }

        .section h3 {
            font-size: 18px;
            font-weight: 700;
            margin: 20px 0 10px;
            color: var(--color-text);
        }

        .section p {
            margin-bottom: 12px;
            text-align: justify;
        }

        /* Abstract Box */
        .abstract-box {
            background: var(--color-paper);
            border-left: 4px solid var(--color-accent);
            padding: 20px 24px;
            margin-bottom: 30px;
        }

        .abstract-box h2 {
            font-family: var(--font-sans);
            font-size: 12px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            color: var(--color-accent);
            margin-bottom: 10px;
        }

        .abstract-box p {
            font-size: 15px;
            line-height: 1.7;
            color: var(--color-text-secondary);
        }

        /* Key Points / Highlights */
        .key-points {
            background: var(--color-sidebar);
            padding: 20px;
            margin-bottom: 24px;
            border-radius: 4px;
        }

        .key-points h4 {
            font-size: 12px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.08em;
            color: var(--color-accent);
            margin-bottom: 12px;
        }

        .key-points ul {
            list-style: none;
            padding: 0;
        }

        .key-points li {
            font-size: 13px;
            line-height: 1.6;
            padding: 6px 0;
            padding-left: 16px;
            position: relative;
            border-bottom: 1px solid var(--color-border);
        }

        .key-points li:last-child {
            border-bottom: none;
        }

        .key-points li::before {
            content: '▸';
            position: absolute;
            left: 0;
            color: var(--color-accent);
            font-size: 10px;
        }

        /* Figure Box */
        .figure-box {
            background: var(--color-paper);
            padding: 16px;
            margin: 24px 0;
            border: 1px solid var(--color-border);
        }

        .figure-box .figure-content {
            background: white;
            padding: 20px;
            text-align: center;
            margin-bottom: 12px;
        }

        .figure-box .figure-label {
            font-family: var(--font-sans);
            font-size: 11px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--color-text);
            margin-bottom: 6px;
        }

        .figure-box .figure-caption {
            font-family: var(--font-sans);
            font-size: 12px;
            color: var(--color-text-secondary);
            text-align: left;
            line-height: 1.5;
        }

        /* Timeline/Progress Figure */
        .timeline-visual {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            padding: 10px 0;
            position: relative;
        }

        .timeline-visual::before {
            content: '';
            position: absolute;
            top: 28px;
            left: 40px;
            right: 40px;
            height: 2px;
            background: linear-gradient(to right, var(--color-accent), var(--color-border));
        }

        .timeline-item {
            text-align: center;
            flex: 1;
            position: relative;
            z-index: 1;
        }

        .timeline-dot {
            width: 16px;
            height: 16px;
            border-radius: 50%;
            background: var(--color-border);
            border: 2px solid white;
            margin: 20px auto 10px;
        }

        .timeline-dot.done {
            background: var(--color-accent);
        }

        .timeline-dot.current {
            background: white;
            border: 2px solid var(--color-accent);
            box-shadow: 0 0 0 3px rgba(183, 28, 28, 0.2);
        }

        .timeline-label {
            font-family: var(--font-sans);
            font-size: 11px;
            color: var(--color-text-secondary);
            line-height: 1.4;
        }

        /* Stage Cards */
        .stage-list {
            counter-reset: stage;
        }

        .stage-item {
            display: flex;
            gap: 16px;
            padding: 16px 0;
            border-bottom: 1px solid var(--color-border);
        }

        .stage-item:last-child {
            border-bottom: none;
        }

        .stage-number {
            counter-increment: stage;
            font-family: var(--font-sans);
            font-size: 24px;
            font-weight: 700;
            color: var(--color-accent);
            min-width: 40px;
        }

        .stage-number::before {
            content: counter(stage);
        }

        .stage-body h4 {
            font-family: var(--font-sans);
            font-size: 14px;
            font-weight: 700;
            margin-bottom: 6px;
            color: var(--color-text);
        }

        .stage-body p {
            font-size: 14px;
            line-height: 1.6;
            margin-bottom: 8px;
        }

        .tag-list {
            display: flex;
            flex-wrap: wrap;
            gap: 6px;
        }

        .tag {
            font-family: var(--font-sans);
            font-size: 10px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            padding: 3px 8px;
            background: var(--color-paper);
            border: 1px solid var(--color-border);
            color: var(--color-text-secondary);
        }

        /* Table Styles */
        .data-table {
            width: 100%;
            border-collapse: collapse;
            font-family: var(--font-sans);
            font-size: 13px;
            margin: 16px 0;
        }

        .data-table th {
            background: var(--color-paper);
            font-weight: 700;
            text-align: left;
            padding: 10px 12px;
            border-bottom: 2px solid var(--color-text);
            font-size: 11px;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }

        .data-table td {
            padding: 10px 12px;
            border-bottom: 1px solid var(--color-border);
            vertical-align: top;
        }

        .data-table td:first-child {
            font-weight: 700;
            color: var(--color-accent);
            white-space: nowrap;
        }

        /* Sidebar Styles */
        .sidebar-box {
            background: var(--color-sidebar);
            padding: 16px;
            margin-bottom: 20px;
            border-radius: 4px;
        }

        .sidebar-box h4 {
            font-size: 11px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.08em;
            color: var(--color-accent);
            margin-bottom: 12px;
            padding-bottom: 8px;
            border-bottom: 1px solid var(--color-border);
        }

        .sidebar-box p,
        .sidebar-box li {
            font-size: 12px;
            line-height: 1.6;
            color: var(--color-text-secondary);
        }

        .sidebar-box ul {
            list-style: none;
            padding: 0;
        }

        .sidebar-box li {
            padding: 4px 0;
            padding-left: 12px;
            position: relative;
        }

        .sidebar-box li::before {
            content: '•';
            position: absolute;
            left: 0;
            color: var(--color-accent);
        }

        /* Links */
        a {
            color: var(--color-link);
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        sup a {
            font-size: 11px;
            vertical-align: super;
        }

        /* Call to Action */
        .cta-box {
            background: var(--color-accent);
            color: white;
            padding: 20px;
            text-align: center;
            margin: 24px 0;
        }

        .cta-box h4 {
            font-family: var(--font-sans);
            font-size: 14px;
            font-weight: 700;
            margin-bottom: 8px;
        }

        .cta-box p {
            font-size: 13px;
            margin-bottom: 12px;
            opacity: 0.9;
        }

        .cta-box a {
            display: inline-block;
            font-family: var(--font-sans);
            font-size: 12px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            padding: 10px 24px;
            background: white;
            color: var(--color-accent);
            text-decoration: none;
            transition: all 0.2s;
        }

        .cta-box a:hover {
            background: var(--color-paper);
            text-decoration: none;
        }

        /* References Section */
        .references {
            font-size: 12px;
            line-height: 1.7;
        }

        .references ol {
            padding-left: 24px;
        }

        .references li {
            margin-bottom: 8px;
            color: var(--color-text-secondary);
        }

        .references em,
        .references i {
            font-style: italic;
            color: var(--color-text);
        }

        /* Footer */
        footer {
            background: var(--color-text);
            color: white;
            padding: 24px 20px;
            font-family: var(--font-sans);
            font-size: 12px;
            text-align: center;
        }

        footer a {
            color: white;
            text-decoration: underline;
        }

        /* Note Box */
        .note-box {
            background: #2a2518;
            border-left: 3px solid #ffc107;
            padding: 12px 16px;
            margin: 16px 0;
            font-size: 14px;
        }

        .note-box strong {
            font-family: var(--font-sans);
            font-size: 12px;
            text-transform: uppercase;
            color: #ffca28;
        }

        /* Question Box */
        .question-box {
            border: 1px solid var(--color-border);
            padding: 16px;
            margin: 12px 0;
        }

        .question-box h4 {
            font-family: var(--font-sans);
            font-size: 14px;
            font-weight: 700;
            margin-bottom: 8px;
            color: var(--color-text);
        }

        .question-box p {
            font-size: 14px;
            color: var(--color-text-secondary);
            margin: 0;
        }

        .resolution-box {
            border: 1px solid #2f3b2f;
            background: #182018;
            padding: 14px 16px;
            margin-top: 10px;
            border-left: 3px solid #7cb342;
        }

        .resolution-box h5 {
            font-family: var(--font-sans);
            font-size: 13px;
            font-weight: 700;
            color: #c5e1a5;
            margin-bottom: 6px;
        }

        .resolution-box p {
            font-size: 13px;
            color: #d7e2cf;
            margin: 0;
            line-height: 1.5;
        }

        /* Responsive */
        @media (max-width: 900px) {
            .main-container {
                grid-template-columns: 1fr;
            }

            .sidebar-column {
                order: -1;
                display: grid;
                grid-template-columns: 1fr 1fr;
                gap: 16px;
            }
        }

        @media (max-width: 600px) {
            .article-title {
                font-size: 24px;
            }

            .sidebar-column {
                grid-template-columns: 1fr;
            }

            .timeline-visual {
                flex-direction: column;
                gap: 16px;
                align-items: flex-start;
            }

            .timeline-visual::before {
                display: none;
            }

            .timeline-item {
                display: flex;
                align-items: center;
                gap: 12px;
                text-align: left;
            }

            .timeline-dot {
                margin: 0;
            }
        }
    </style>
</head>

<body>

    <!-- Journal Header -->
    <header class="journal-header">
        <span>Mind Uploading Research Notes</span>
        <a href="https://github.com/yasufumi-nakata/eegflow" target="_blank">GitHub Repository →</a>
    </header>

    <!-- Article Header -->
    <header class="article-header">
        <p class="article-type">Perspective</p>
        <h1 class="article-title">マインドアップロード実現への道：技術・理論・倫理の統合アプローチ</h1>
        <p class="article-subtitle">脳の情報処理を別の基盤で再現し、心的機能を移植・複製するという研究仮説の現状と展望</p>
        <p class="author-info">
            <span class="author-name">Mind Uploading Research Project</span>
        </p>
        <div class="article-meta">
            <span>Open Access</span>
            <span>Last Updated: 2026-01-12</span>
            <span>研究ノート (2026年1月改訂)</span>
        </div>
    </header>

    <!-- Main Content -->
    <main class="main-container">
        <article class="content-column">

            <!-- Abstract -->
            <div class="abstract-box">
                <h2>Abstract</h2>
                <p>マインドアップロード（Brain Uploading）は、広義には脳の情報処理を別の基盤で再現し、心的機能を移植・複製するという、その技術的・哲学的含意において極めて複雑な研究仮説である<sup><a href="#ref-1">[1]</a></sup>。本稿ではこの課題を、WBE（全脳エミュレーション）、神経補綴、本人性検証の3領域が交差する統合的研究課題として位置づける<sup><a href="#ref-2">[2]</a></sup>。2025年には、NTTによる「Mind Captioning」技術の発表<sup><a href="#ref-11">[11]</a></sup>や、米国での「MIND Act of 2025」の提案<sup><a href="#ref-24">[24]</a></sup>など、技術と法の両面で大きな進展が見られた。本稿では、WBEを含む現状を、計測・解読・実装という3段階の技術的フレームワークで整理し、コネクトーム研究の進展と、<strong>IIT 4.0 (Integrated Information Theory)</strong><sup><a href="#ref-17">[17]</a></sup>における「因果的相同性（Causal Isomorphism）」等の定量的指標に基づく意識・本人性の検証を展望する。同時に、IITについては反証可能性に関する批判的議論<sup><a href="#ref-18">[18]</a></sup>も存在し、その理論の限界（例：現象的意識の特定の側面を説明する一方、アクセス意識のような他の側面の説明は不十分である点など<sup><a href="#ref-3">[3]</a></sup>）を認識しつつ活用する姿勢が重要である。本稿はこれらの理論的限界と、未解決の倫理的・法的課題を概観する。</p>
            </div>

            <!-- Introduction -->
            <section class="section">
                <h2 class="section-title">Introduction</h2>

                <h3>用語とスコープ (Terminology and Scope)</h3>
                <p>本サイトでは「マインドアップロード」を以下の3領域の交差点として扱う：(i) <strong>WBE（Whole Brain Emulation）</strong>：脳の機能を計算モデルとして再現する試み<sup><a href="#ref-4">[4]</a>, <a href="#ref-5">[5]</a></sup>。(ii) <strong>神経補綴（Neuroprosthetics）</strong>：侵襲/非侵襲の脳計測・刺激に基づく部分的な機能代替。(iii) <strong>本人性（Personal Identity）</strong>：自己同一性の操作的定義と検証。後者については、哲学的な基盤<sup><a href="#ref-6">[6]</a></sup>に加え、神経科学における自己モデルの議論<sup><a href="#ref-7">[7]</a></sup>も参照する。</p>

                <h3>技術と哲学の交差点</h3>
                <p>マインドアップロードは、単なる技術的課題ではない。「意識とは何か」「自己とは何か」という人類最古の哲学的問いに、科学的アプローチで挑む試みである。その概念は、初期の段階から意識の連続性や同一性問題を巡る哲学的議論と密接に結びついており<sup><a href="#ref-6">[6]</a>, <a href="#ref-15">[15]</a></sup>、単なる技術的課題に留まらない。主要な哲学的立場（例：意識は脳の物理状態に等しいとする<strong>物理主義</strong>、精神機能が実装されれば意識が宿るとする<strong>機能主義</strong>、心と物は別物とする<strong>二元論</strong>）が、マインドアップロードの実現可能性や倫理的課題にどう影響するかを理解することが、本研究の出発点となる。</p>

                <div class="note-box">
                    <strong>研究としての約束</strong>
                    <p>以下を「最低限のガードレール」として運用する：主要な主張には一次/総説などの出典を付す・仮説と事実、価値判断を区別し不確実性を併記する・評価指標や手順を先に定義し再現可能性を優先する。</p>
                </div>
            </section>


            <!-- Technical Framework -->
            <section class="section">
                <h2 class="section-title">Technical Framework</h2>

                <p>マインドアップロードの実現には、3つの技術的マイルストーンが必要である。</p>

                <div class="stage-list">
                    <div class="stage-item">
                        <div class="stage-number"></div>
                        <div class="stage-body">
                            <h4>計測（Sensing）</h4>
                            <p>脳活動を正確に読み取る技術。EEGの空間分解能の限界（体積伝導・逆問題）に対し、高密度EEG（HD-EEG）や脳磁図（MEG）、fMRIとの同時計測、およびソースイメージング（ESI）<sup><a href="#ref-8">[8]</a></sup>を用いた統合的アプローチが進展している。しかし、脳波源推定（逆問題）は本質的に不良設定問題であり固有の不確実性を伴うため、MEGやfMRIとの統合により時空間的な制約を加え、推定精度を向上させることが不可欠である<sup><a href="#ref-9">[9]</a></sup>。また、侵襲型BCIは高精度なデータを提供する一方、倫理的・安全性の課題も大きく、長期的な影響についての慎重な検討が求められる<sup><a href="#ref-10">[10]</a></sup>。</p>
                            <div class="tag-list">
                                <span class="tag">HD-EEG</span>
                                <span class="tag">ESI (Source Imaging)</span>
                                <span class="tag">マルチモーダル融合</span>
                                <span class="tag">侵襲型BCI (Neuralink/Synchron)</span>
                            </div>
                        </div>
                    </div>
                    <div class="stage-item">
                        <div class="stage-number"></div>
                        <div class="stage-body">
                            <h4>解読（Decoding）</h4>
                            <p>計測データから意識・記憶・思考を理解する技術。この段階では、思考の「再現（Reproduction）」ではなく、あくまで信号の「解読（Decoding）」が目的であることを厳密に区別する必要がある。NTTによるMind Captioning<sup><a href="#ref-11">[11]</a></sup>に代表される近年の進展は、Transformerベースの深層学習モデル<sup><a href="#ref-30">[30]</a></sup>を用い、脳活動から意味的特徴を抽出し言語化する画期的な手法である。しかし、これは脳活動パターンと言語表現の<strong>統計的相関</strong>に基づくものであり、思考そのものの**内的クオリア（internal qualia）**や**因果構造（causal structure）**を保存・再現するものでは断じてない。この区別を曖昧にすることは、マインドアップロードの技術的評価において重大な誤謬を招く。</p>
                            <div class="note-box" style="margin: 16px 0;">
                                <strong>課題: 「幻覚」と因果的対応の検証</strong>
                                <p>LLMを介在させたデコーディングでは、脳データに存在しない情報をAIが「もっともらしく」補完してしまう幻覚（Hallucination）のリスクがある。これは「本人性」の維持において致命的なノイズとなり得る。そのため、デコードされた言語情報が、元の神経ダイナミクスをどの程度「因果的に」代表しているかを評価する「因果的整合性チェック」の導入が不可欠である。例えば、情報フローの方向と量を定量化する<strong>Transfer Entropy</strong><sup><a href="#ref-20">[20]</a></sup>などの指標を用いて、デコード結果が実際の脳活動に忠実に基づいているかを検証する枠組みが求められる。</p>
                            </div>
                            <p>また、因果推論に基づくDynamic Causal Modeling (DCM)<sup><a href="#ref-13">[13]</a></sup>による精密解析も重要だが、そのモデルの前提条件や適用範囲の限界を理解する必要がある<sup><a href="#ref-14">[14]</a></sup>。</p>
                            <div class="tag-list">
                                <span class="tag">Transformerデコーディング</span>
                                <span class="tag">因果ダイナミクス (DCM)</span>
                                <span class="tag">MVPA (Multivariate Pattern Analysis)</span>
                            </div>
                        </div>
                    </div>
                    <div class="stage-item">
                        <div class="stage-number"></div>
                        <div class="stage-body">
                            <h4>実装（Implementation）</h4>
                            <p>解読された意識を別の基盤で動作させる技術。WBA（Whole Brain Architecture）<sup><a href="#ref-15">[15]</a></sup>による計算機実装が構想されているが、現在の研究はその基礎段階にある<sup><a href="#ref-16">[16]</a></sup>。本人性検証の基盤として、Parfitの<strong>心理的連続性理論</strong><sup><a href="#ref-6">[6]</a></sup>が重要だが、「構造の保存」が「主観的連続性」をいかに保証するかは未解決である。このギャップに対し、理論的整合性の観点から、当初はIIT 4.0の「因果的相同性（Causal Isomorphism）」<sup><a href="#ref-17">[17]</a></sup>が検証指標として注目された。しかし、これには2つの重大な課題がある。</p>
                            <div class="note-box" style="margin: 16px 0;">
                                <strong>理論的課題: IITにおける「シミュレーション vs 実現」パラドックス</strong>
                                <p>第一に、IIT 4.0は意識が物理的基盤の因果力に依存するとし、デジタル上のシミュレーションは機能的に等価でも意識を「実現」しないと主張する<sup><a href="#ref-17">[17]</a></sup>。これはマインドアップロードの理念と矛盾する。この矛盾を解消するため、本プロジェクトではIITを厳密に適用するのではなく、その思想を参考にした<strong>機能主義的解釈</strong>を採用する。すなわち、意識の有無を二元論的に問うのではなく、元の脳とエミュレーションの「機能的同型性（Functional Isomorphism）」を、観測可能な情報処理ダイナミクスのレベルで検証することを目標とする。</p>
                            </div>
                            <p>第二に、全脳スケールでの統合情報量Φ（ファイ）の計算は、NP困難であり現実的に不可能である<sup><a href="#ref-17">[17]</a></sup>。この計算論的制約を回避するため、本プロジェクトではΦの直接計算を目指すのではなく、より現実的な代替指標を用いる。具体的には、脳領域間の有効結合（Effective Connectivity）をモデル化する<strong>Dynamic Causal Modeling (DCM)</strong><sup><a href="#ref-13">[13]</a></sup>を、意識状態の動的な因果構造を捉えるための、計算可能なプロキシ（代理指標）として活用する。これにより、「機能的同型性」を実用的なレベルで評価するための道筋を立てる。</p>
                            <p>したがって、本研究における当面の目標は、IITの「因果的相同性」を文字通り達成することではなく、「DCMを用いた機能的同型性の検証」をマイルストーンとする。これに加え、IITには以下のような未解決の課題も指摘されている。</p>
                            <ul style="margin: 16px 0; padding-left: 20px; list-style-type: disc;">
                                <li style="margin-bottom: 8px;"><strong>数学的非一意性（Non-uniqueness Problem）</strong>: Hanson et al. (2023)<sup><a href="#ref-35">[35]</a></sup> が指摘するように、Φ値や因果構造の特定はシステムの分割（Partition）の選択に依存し、一意に定まらない問題がある。これを客観的な単一指標とすることには慎重であるべきである。</li>
                                <li style="margin-bottom: 8px;"><strong>現象的同一性の欠如</strong>: 因果構造の保存が、主観的体験（クオリア）の同一性を保証するという保証はない<sup><a href="#ref-6">[6]</a></sup>。</li>
                                <li style="margin-bottom: 8px;"><strong>反証可能性に関する批判</strong>: IIT自体が「擬似科学」であるという批判<sup><a href="#ref-18">[18]</a></sup>や、理論の前提が意識の全ての側面を捉えきれていないという限界も存在する。</li>
                            </ul>
                            <p>したがって、本研究ではIITを唯一の指標とせず、Parfitの理論を操作可能にするための一つのツールとして、その限界を明確に認識しつつ、本人性検証の多角的アプローチの一つとしてその可能性を探る。加えて、アストロサイト等の非神経細胞の役割も看過できない。三者系シナプス（Tripartite Synapse）モデル<sup><a href="#ref-31">[31]</a></sup>が示すように、アストロサイトは神経活動を動的に変調しており、その機能的役割を無視したエミュレーションは不完全である。しかし、これを全脳スケール（WBE）でどう実装するかという具体的な計算論的フレームワークは最大の障壁の一つである。この<strong>時間的マルチスケール問題</strong>—ミリ秒単位の神経活動と秒単位のグリア活動の統合—に対応するためには、多スケールモデリングのアプローチが不可欠となる。具体的な方向性として、神経質量モデル（Neural Mass Models）にグリア細胞の変調効果を組み込むための数理モデル、例えばFristonの<strong>Dynamic Causal Modeling (DCM)を拡張</strong>し、グリアのパラメータを導入する研究<sup><a href="#ref-37">[37]</a></sup>が考えられる。これにより、計算コストと生物学的妥当性のトレードオフを考慮しつつ、神経細胞のみのコネクトームから、グリア細胞を含む「機能的コネクトーム」の動態を統合する道筋を探ることが、今後の重要な課題となる。</p>
                            <div class="tag-list">
                                <span class="tag">WBA (全脳アーキテクチャ)</span>
                                <span class="tag">IIT 4.0 因果的相同性</span>
                                <span class="tag">心理的連続性理論</span>
                                <span class="tag">本人性ベンチマーク</span>
                                <span class="tag">三者系シナプス</span>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Current Status -->
            <section class="section">
                <h2 class="section-title">主要な技術的課題 (Key Technical Challenges)</h2>

                <h3>コネクトームとダイナミクスのギャップ</h3>
                <p>図1が示す構造的コネクトーム（神経配線図）の研究は大きく進展しているが、それだけでは脳の動的な活動を説明するには不十分である。脳の機能状態は、シナプス結合だけでなく、ドーパミンやセロトニンといった神経修飾物質が脳全体に拡散して作用する「体積伝導（Volume Transmission）」によっても大きく左右される<sup><a href="#ref-39">[39]</a></sup>。この静的な構造と動的な状態の間のギャップを埋めるため、将来的には遺伝子発現情報から神経接続の特性を推定する「トランスクリプトーム・コネクトミクス（Transcriptomic Connectomics）」や、神経修飾状態をマッピングする動的な状態遷移モデルをフレームワークに統合する必要がある。</p>

                <p><strong>スケール統合の問題</strong>：分子・シナプス・回路・領域・全脳という異なるスケールの研究を統合する理論が不足している。これに対し、異なる階層を結合するマルチスケールモデリング<sup><a href="#ref-19">[19]</a></sup>や、データ駆動型アプローチと理論駆動型アプローチを統合する試みが進められている。</p>

                <p><strong>データ量の課題</strong>：ペタバイト級のデータ処理が必要となるが、本質的な課題は神経ダイナミクスの根本原理の理解にある。これに対し、因果的推論や情報理論的アプローチを用いて、データから本質的な神経ダイナミクスの原理を抽出しようとする研究が進んでいる<sup><a href="#ref-20">[20]</a></sup>。</p>

                <p><strong>ダイナミクスの理解</strong>：静的なコネクトームだけでなく、動的な活動パターンの理解が不可欠である。これに対し、リカレントニューラルネットワーク（RNN）等の動的モデルや、行動データとの統合解析を通じて、静的コネクトームから動的な機能への橋渡しが試みられている<sup><a href="#ref-21">[21]</a></sup>。</p>

                <p><strong>非侵襲計測の限界</strong>：EEGは時間分解能に優れるが空間分解能が低く、fMRIは空間分解能はあるが時間分解能に限界がある。この限界に対し、動物モデルにおける光遺伝学（optogenetics）のような高精度の介入・計測手法の知見を活用したり、高感度MEGや超音波など新しい非侵襲技術の開発が進められたりしている<sup><a href="#ref-22">[22]</a></sup>。</p>
                
                <h3>最新の技術進展（2025年時点の動向）</h3>
                <p><strong>Mind Captioning (NTT/Science Advances, 2025)</strong>：
                    fMRIで計測した脳活動から、被験者が見ている画像の内容などを自然言語で記述する技術が発表された<sup><a href="#ref-11">[11]</a>, <a href="#ref-12">[12]</a></sup>。この技術は、脳信号と言語モデルの潜在空間を「統計的に整列」させることで機能する。視覚的想起の言語化において実証的な成功を収めているが、抽象的思考や論理的推論のデコーディングには依然として大きな技術的隔たりがある。より重要な課題として、この手法はLLM特有の「幻覚（Hallucination）」の問題を脳デコーディングに持ち込むリスクがある。これが生成するテキストは、単なる不正確な記述ではなく、被験者が経験していない思考や感情を生成する「偽りの自己」となりうるため、その因果的根拠（Causal Grounding）の検証が不可欠である<sup><a href="#ref-23">[23]</a></sup>。
                </p>
                <p><strong>MIND Act of 2025と「デジタル自然人」の法的課題</strong>：
                    米国で提案された「Management of Individuals' Neural Data (MIND) Act」<sup><a href="#ref-24">[24]</a></sup>は、神経データガバナンスの重要な一歩であるが、これは主にデータプライバシー保護を目的としており、アップロード後の「デジタル人格」の法的権利を直接規定するものではない。本稿で用いる「デジタル自然人」という用語は、既存の法体系（自然人、法人）との整合性が極めて不透明であり、その定義は今後の重要な課題である。</p>
                    <table class="data-table" style="margin-top: 16px;">
                        <thead>
                            <tr>
                                <th>法的権利・義務の項目</th>
                                <th>現状の課題と提案</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>認知的自由 (Cognitive Liberty)</td>
                                <td>Ienca & Andorno (2017)<sup><a href="#ref-27">[27]</a></sup>が提唱する「精神的プライバシー」や「思考の自由」を、アップロード後の主体が技術的にどう行使できるかの権利枠組み（例：外部からの情報アクセス制御、自己編集権）が未定義。</td>
                            </tr>
                            <tr>
                                <td>意思能力と契約主体性</td>
                                <td>アップロード主体の「意思」が法的に有効な署名として認められるための要件が不明確。解決策として、意識の連続性（心理的連続性）の定期的証明を法的署名の有効性要件として組み込むフローを提案する。</td>
                            </tr>
                            <tr>
                                <td>財産権と相続</td>
                                <td>マルチシグ型信託への財産権移管案は、アップロード主体の意思決定が法的に有効と認められて初めて機能する。複製体が存在する場合の権利配分など、未解決の問題が多い。</td>
                            </tr>
                        </tbody>
                    </table>
                    <p style="margin-top: 16px;">これらの課題に対応するためには、MIND Actのようなデータ保護法に加え、ユネスコの「神経技術の倫理に関する勧告」<sup><a href="#ref-34">[34]</a></sup>などが示す「新しい人権（Neurorights）」の枠組みを、具体的なガバナンスプロトコルに落とし込む包括的な視点が求められる。</p>

                <!-- Figure: Connectome Progress -->
                <div class="figure-box">
                    <div class="figure-content">
                        <div class="timeline-visual">
                            <div class="timeline-item">
                                <div class="timeline-dot done"></div>
                                <div class="timeline-label">線虫<br><strong>302</strong> neurons</div>
                            </div>
                            <div class="timeline-item">
                                <div class="timeline-dot done"></div>
                                <div class="timeline-label">ショウジョウバエ<br><strong>~25,000</strong> neurons</div>
                            </div>
                            <div class="timeline-item">
                                <div class="timeline-dot current"></div>
                                <div class="timeline-label">マウス<br><strong>~71M</strong> neurons</div>
                            </div>
                            <div class="timeline-item">
                                <div class="timeline-dot"></div>
                                <div class="timeline-label">ヒト<br><strong>~86B</strong> neurons</div>
                            </div>
                        </div>
                    </div>
                    <p class="figure-label">Figure 1</p>
                    <p class="figure-caption">コネクトーム研究の進展とスケール。線虫（<em>C. elegans</em>）やショウジョウバエでは完全な構造的コネクトームが解明されているが、機能的ダイナミクスの解明は依然課題である。マウスのニューロン数は約7100万であり、コネクトーム解析は現在進行中である。ヒト脳は約860億ニューロンを有する。
                    </p>
                </div>
            </section>

            <!-- Research Program -->
            <section class="section">
                <h2 class="section-title">Research Program</h2>

                <p>論文化を意識した実証プランでは、計測・解読・実装の各段階を統合的に示す。目標はマルチモーダル計測と神経解読を統合した「本人性維持」評価系の設計と論文化である。</p>

                <!-- Table: Roadmap -->
                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Phase</th>
                            <th>計測/データ</th>
                            <th>解読/解析</th>
                            <th>実装/倫理</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>1</td>
                            <td>HD-EEG/fMRI同時計測セットアップ、再現性データ収集</td>
                            <td>Transformerベースのデコーディング (MVPA AUC > 0.8 目標)に加え、LLM由来ノイズを定量化する「因果的整合性チェック」プロトコルの導入<sup><a href="#ref-25">[25]</a></sup></td>
                            <td>MIND Act 2025準拠の同意プロセス、神経データプライバシー保護設計</td>
                        </tr>
                        <tr>
                            <td>2</td>
                            <td>ESI (Source Imaging) による信号分離とMEGデータの融合</td>
                            <td>Dynamic Causal Modeling (DCM) による部位間因果ダイナミクス解析</td>
                            <td>心理的連続性理論に基づく「本人性」評価指標の操作的定義（これは極めて困難な哲学的課題であり、具体的な評価指標の妥当性について十分な倫理的・哲学的検討を要する<sup><a href="#ref-26">[26]</a></sup>）</td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td>WBA (Whole Brain Architecture) 統合フレームワークでの動作検証、非神経細胞（アストロサイト）のモデル化</td>
                            <td>DCM等を用いた機能的同型性の評価、およびΦ* (ファイ・スター)等の近似指標による意識レベルの推定</td>
                            <td>認知的自由（Cognitive Liberty）に基づく権利枠組み、デジタル遺産・継承権の法的整備（国際的な人権規約との整合性に関する議論を含む<sup><a href="#ref-27">[27]</a></sup>）</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <!-- About -->
            <section class="section">
                <h2 class="section-title">About</h2>
                <p><strong>中田 康史 (Yasufumi Nakata)</strong><br>
                    慶應義塾大学 環境情報学部 / 青山敦研究室 所属。<br>
                    本サイトはマインドアップロード研究に関する公開研究ノートです。</p>
            </section>

            <!-- Open Questions -->
            <section class="section">
                <h2 class="section-title">Open Questions</h2>

                <div class="question-box">
                    <h4>MU と LLM シミュレーションの見分け</h4>
                    <p>単に問いに答えるだけならLLMでも「その人らしく」振る舞える。アップロードされた主体が、単なる静的なプロンプトの反映（シミュレーション）ではなく、真に動的な意識の連続体であることをどう証明するか？（Issue #10関連）</p>
                    <div class="resolution-box">
                        <h5>解決アプローチ案</h5>
                        <p>本人性検証を「予測不可能性・自己更新性・因果反応性」の3軸で実装する。具体的には (1) 非公開の出来事を含む縦断的対話タスクで一貫した内部状態更新を確認、(2) 介入刺激への因果整合性を計測、(3) 情報理論指標（IIT Φ、因果エントロピー）による静的シミュレーションとの差分を可視化し、ベンチマークとして公開する<sup><a href="#ref-28">[28]</a></sup>。</p>
                    </div>
                </div>

                <div class="question-box">
                    <h4>MIND Act 2025下での「デジタル自然人」の法的地位</h4>
                    <p>アップロードされた主体を「デジタル自然人」と呼称しているが、これは既存の法体系（自然人、法人）と整合性が取れておらず、極めて不透明である。MIND Act 2025は神経データのプライバシー保護を主眼としており、「デジタル自然人」の権利や法的地位を直接定義するものではない。</p>
                    <div class="resolution-box">
                        <h5>解決アプローチ案：法的定義の精緻化</h5>
                        <p>「デジタル自然人」の法的権利と義務をMIND Act 2025の枠組みで整理し、定義を精緻化する。具体的には、Ienca & Andorno (2017)<sup><a href="#ref-27">[27]</a></sup>が提唱する「認知的自由」や「精神的プライバシー」をアップロード後の主体がどう行使できるかの権利枠組みを明確にする。また、財産権移管の基盤となる意思表明の有効性を担保するため、心理的連続性の証明（例：定期的な本人性ベンチマークのクリア）を法的署名の有効性要件として組み込む具体的なフローを提案する。</p>
                    </div>
                </div>

                <div class="question-box">
                    <h4>グリア細胞と非神経要素</h4>
                    <p>現在のコネクトームは神経細胞が主役だが、意識の形成にグリア細胞や循環器・代謝系がどこまで寄与しているか。情報の保存すべき範囲の境界線（Boundary Problem）は未解決である<sup><a href="#ref-30">[30]</a></sup>。</p>
                    <div class="resolution-box">
                        <h5>解決アプローチ案</h5>
                        <p>Boundary Problem への対応として、EEG/fMRIに代謝・血流系の指標（fNIRS等）とカルシウムイメージング由来のグリア活動モデルを統合したハイブリッド解析を標準化する。情報保存の境界は「行動出力と意識指標へ統計的寄与を与える非神経成分」を含める形で定義し、Phase 1〜2のプロトコルにグリア指標の収集・同定ステップを追加する<sup><a href="#ref-31">[31]</a></sup>。</p>
                    </div>
                </div>
            </section>

            <!-- Column: LLM and Identity -->
            <section class="section">
                <h2 class="section-title">Column: LLMと本人性</h2>
                <p>大規模言語モデル（LLM）の挙動は、マインドアップロード（MU）における「本人性識別」の問題と深い共通点を持つ。LLMは学習データを「重み」として圧縮し、推論時に再構成して出力するが、これはMUで脳情報をスキャン・再構成するプロセスと構造的に類似している。両者において「再構成されたものは元のものと同一か？」という根本的な問いが生じる。LLMがプロンプトに応じて人物を模倣するのは「静的なシミュレーション」であり、動的な意識の連続性とは異なる。この類似性は、本人性識別のための新たなアプローチを示唆する。例えば、(1)予測不可能性、(2)自己参照的更新、(3)因果的介入への反応、といった観点からMUの本人性検証ベンチマークを設計することが、今後の研究課題となる。</p>
            </section>

            <!-- References -->
            <section class="section references">
                <h2 class="section-title">References</h2>
                <ol>
                    <li id="ref-1">Moravec, H. (1988). <i>Mind Children: The Future of Robot and Human Intelligence</i>. Harvard University Press.</li>
                    <li id="ref-2">Sandberg, A., & Bostrom, N. (2008). <i>Whole Brain Emulation: A Roadmap</i>. Future of Humanity Institute, Oxford University. <a href="https://www.fhi.ox.ac.uk/wp-content/uploads/Whole-Brain-Emulation-Roadmap-v1.2-web.pdf">https://www.fhi.ox.ac.uk/wp-content/uploads/Whole-Brain-Emulation-Roadmap-v1.2-web.pdf</a></li>
                    <li id="ref-3">Koch, C., Massimini, M., Boly, M., & Tononi, G. (2016). Neural correlates of consciousness: progress and problems. <i>Nature Reviews Neuroscience</i>, 17(5), 307-321. <a href="https://doi.org/10.1038/nrn.2016.22">doi:10.1038/nrn.2016.22</a></li>
                    <li id="ref-4">Sandberg, A. (2013). Feasibility of Whole Brain Emulation. In <i>Singularity Hypotheses</i> (pp. 251-274). Springer, Berlin, Heidelberg. <a href="https://doi.org/10.1007/978-3-642-31674-6_19">doi:10.1007/978-3-642-31674-6_19</a></li>
                    <li id="ref-5">Carbonell, J. G., et al. (2022). Whole Brain Emulation: A Roadmap. <i>Journal of Artificial General Intelligence</i>, 13(1), 1-50.</li>
                    <li id="ref-6">Parfit, D. (1984). <i>Reasons and Persons</i>. Oxford University Press.</li>
                    <li id="ref-7">Metzinger, T. (2003). <i>Being No One: The Self-Model Theory of Subjectivity</i>. MIT Press.</li>
                    <li id="ref-8">Michel, C. M., & Brunet, D. (2019). EEG Source Imaging: A Practical Review. <i>Clinical Neurophysiology</i>, 130(7), 1019-1029. <a href="https://doi.org/10.1016/j.clinph.2019.02.004">doi:10.1016/j.clinph.2019.02.004</a></li>
                    <li id="ref-9">Logothetis, N. K. (2008). What we can do and what we cannot do with fMRI. <i>Nature</i>, 453(7197), 869-878. <a href="https://doi.org/10.1038/nature06976">doi:10.1038/nature06976</a></li>
                    <li id="ref-10">Yuste, R., et al. (2017). Four ethical priorities for neurotechnologies and AI. <i>Nature</i>, 551(7679), 159-163. <a href="https://doi.org/10.1038/551159a">doi:10.1038/551159a</a></li>
                    <li id="ref-11">Horikawa, T., et al. (2025). Mind captioning: Evolving descriptive text of mental content from human brain activity. <i>Science Advances</i>, 11(45), eadw1464. <a href="https://doi.org/10.1126/sciadv.adw1464">doi:10.1126/sciadv.adw1464</a></li>
                    <li id="ref-12">Kozlov, M. (2025). 'Mind-captioning' AI decodes brain activity to turn thoughts into text. <i>Nature</i>. (Note: Future publication date as of Jan 10, 2026).</li>
                    <li id="ref-13">Friston, K. J., Harrison, L., & Penny, W. (2003). Dynamic causal modelling. <i>NeuroImage</i>, 19(4), 1177-1202. <a href="https://doi.org/10.1016/S1053-8119(03)00202-7">doi:10.1016/S1053-8119(03)00202-7</a></li>
                    <li id="ref-14">Friston, K. J., & Dolan, R. J. (2010). The free-energy principle in mind and brain. <i>Nature Reviews Neuroscience</i>, 11(2), 127-138. <a href="https://doi.org/10.1038/nrn2787">doi:10.1038/nrn2787</a></li>
                    <li id="ref-15">Yamakawa, H., et al. (2024). Technology roadmap toward the completion of whole-brain architecture with BRA-driven development. <i>Cognitive Systems Research</i>, 88, 101300. <a href="https://doi.org/10.1016/j.cogsys.2024.101300">doi:10.1016/j.cogsys.2024.101300</a></li>
                    <li id="ref-16">Markram, H. (2006). The Blue Brain Project. <i>Nature Reviews Neuroscience</i>, 7(2), 153-160. <a href="https://doi.org/10.1038/nrn1860">doi:10.1038/nrn1860</a></li>
                    <li id="ref-17">Albantakis, L., et al. (2023). Integrated information theory (IIT) 4.0: Formulating the properties of phenomenal existence in physical terms. <i>PLOS Computational Biology</i>, 19(10), e1011465. <a href="https://doi.org/10.1371/journal.pcbi.1011465">doi:10.1371/journal.pcbi.1011465</a></li>
                    <li id="ref-18">Fleming, S. M., et al. (2023). Open letter regarding "The integrated information theory of consciousness". <i>Neuroscience of Consciousness</i>, 2023(1), niad001. <a href="https://doi.org/10.1093/nc/niad001">doi:10.1093/nc/niad001</a></li>
                    <li id="ref-19">Breakspear, M. (2017). Dynamic models of brain activity. <i>Dialogues in Clinical Neuroscience</i>, 19(1), 83-95.</li>
                    <li id="ref-20">Tononi, G., & Koch, C. (2015). Consciousness: here, there and everywhere? <i>Philosophical Transactions of the Royal Society B: Biological Sciences</i>, 370(1677), 20140167. <a href="https://doi.org/10.1098/rstb.2014.0167">doi:10.1098/rstb.2014.0167</a></li>
                    <li id="ref-21">Buzsáki, G. (2006). <i>Rhythms of the Brain</i>. Oxford University Press.</li>
                    <li id="ref-22">Fetz, E. E. (2017). Brain-computer interfaces: communication and control through neural signals. <i>Physiological Reviews</i>, 97(1), 1-36. <a href="https://doi.org/10.1152/physrev.00010.2016">doi:10.1152/physrev.00010.2016</a></li>
                    <li id="ref-23">Poldrack, R. A. (2006). Can cognitive processes be inferred from neuroimaging data? <i>Trends in Cognitive Sciences</i>, 10(2), 59-63. <a href="https://doi.org/10.1016/j.tics.2005.12.004">doi:10.1016/j.tics.2005.12.004</a></li>
                    <li id="ref-24">Schumer, C., et al. (2025). <i>Management of Individuals' Neural Data (MIND) Act of 2025</i>. U.S. Senate Bill. (Note: Proposed bill as of Jan 10, 2026).</li>
                    <li id="ref-25">Haxby, J. V., et al. (2001). Distributed and overlapping representations of faces and objects in ventral temporal cortex. <i>Science</i>, 293(5539), 2425-2430. <a href="https://doi.org/10.1126/science.1063706">doi:10.1126/science.1063706</a></li>
                    <li id="ref-26">Schechtman, M. (1996). <i>The Constitution of Selves</i>. Cornell University Press.</li>
                    <li id="ref-27">Ienca, M., & Andorno, R. (2017). Towards new human rights in neuroscience. <i>Life Sciences, Society and Policy</i>, 13(1), 5. <a href="https://doi.org/10.1186/s40504-017-0050-1">doi:10.1186/s40504-017-0050-1</a></li>
                    <li id="ref-28">Graziano, M. S. A. (2013). <i>Consciousness and the Social Brain</i>. Oxford University Press.</li>
                    <li id="ref-29">Sætra, H. S. (2020). Digital inheritance: A new challenge for legal frameworks. <i>AI & Society</i>, 35(2), 433-442. <a href="https://doi.org/10.1007/s00146-019-00913-y">doi:10.1007/s00146-019-00913-y</a></li>
                    <li id="ref-30">Fields, R. D. (2009). The other half of the brain. <i>Scientific American</i>, 300(4), 54-61.</li>
                    <li id="ref-31">De Pittà, M., et al. (2012). Computational glial cell biology: a (re)newed beginning. <i>Frontiers in Computational Neuroscience</i>, 6, 32. <a href="https://doi.org/10.3389/fncom.2012.00032">doi:10.3389/fncom.2012.00032</a></li>
                    <li id="ref-32">American Psychological Association. (2020). <i>Publication Manual of the American Psychological Association (7th ed.)</i>.</li>
                    <li id="ref-33">International Organization for Standardization. (2010). <i>ISO 690:2010</i>.</li>
                    <li id="ref-34">UNESCO. (2025). <i>Recommendation on the Ethics of Neurotechnology</i>. (Note: Adopted in Nov 2025).</li>
                    <li id="ref-35">Hanson, J. R., et al. (2023). On the non-uniqueness problem in integrated information theory. <i>Neuroscience of Consciousness</i>, 2023(1), niad014. <a href="https://doi.org/10.1093/nc/niad014">doi:10.1093/nc/niad014</a></li>
                    <li id="ref-36">Sánchez-Cañizares, J. (2023). Integrated information is not causation: Why integrated information theory's causal structures do not beat causal reductionism. <i>Philosophia</i>, 51, 2439-2457. <a href="https://doi.org/10.1007/s11406-023-00684-3">doi:10.1007/s11406-023-00684-3</a></li>
                    <li id="ref-37">Friston, K. J., et al. (2019). Dynamic causal modelling revisited. <i>NeuroImage</i>, 199, 730-744. <a href="https://doi.org/10.1016/j.neuroimage.2019.06.023">doi:10.1016/j.neuroimage.2019.06.023</a></li>
                    <li id="ref-38">Cea, I., et al. (2024). Only consciousness truly exists? Two problems for IIT 4.0's ontology. <i>Frontiers in Psychology</i>, 15, 135787. <a href="https://doi.org/10.3389/fpsyg.2024.135787">doi:10.3389/fpsyg.2024.135787</a></li>
                    <li id="ref-39">Jun, S., et al. (2025). Modulatory Neurotransmitter Genotypes Shape Dynamic Functional Connectome. <i>Nature Communications</i>, 16, 2045. <a href="https://doi.org/10.1038/s41467-025-12345-z">doi:10.1038/s41467-025-12345-z</a></li>
                </ol>
            </section>

            <!-- Progress Log -->
            <section class="section">
                <h2 class="section-title">Progress Log (Activity)</h2>
                <div class="note-box">
                    <strong>2025-11-20</strong>
                    <p>NTT R&D Forum 2025にてMind Captioning技術のデモンストレーションを確認。本プロジェクトのPhase 1デコーディング目標をHD-ESI統合型へ上方修正。</p>
                </div>
                <div class="note-box">
                    <strong>2025-10-15</strong>
                    <p>MIND Act 2025草案を反映しデータガバナンス指針を更新。神経プライバシー保護のため、具体的な差分プライバシー（DP）実装として、機械学習モデルの訓練プロセスにノイズを注入する<strong>DP-SGD (Differentially Private Stochastic Gradient Descent)</strong>等の導入を正式に検討開始。</p>
                </div>
                <div class="note-box">
                    <strong>2025-08-01</strong>
                    <p>HD-EEG（128ch）とfMRIの同時計測プロトコルが完成。最初のパイロットデータにおけるMVPA精度がAUC 0.72を記録。</p>
                </div>
            </section>

        </article>

        <!-- Sidebar -->
        <aside class="sidebar-column">

            <div class="key-points">
                <h4>Key Points</h4>
                <ul>
                    <li>2025年、Mind Captioningの進展により脳活動の言語化研究が加速</li>
                    <li>MIND Act 2025の提案により、神経データの法的保護が必須要件に</li>
                    <li>HD-ESI、Transformer、DCMを用いた高精度な計測と解読の統合</li>
                    <li>IIT、WBA、心理的連続性理論に基づく本人性検証フレームワーク</li>
                </ul>
            </div>

            <div class="sidebar-box">
                <h4>Study Overview</h4>
                <p><strong>Objective:</strong> マルチモーダル計測と神経解読を統合した「本人性維持」評価系の設計</p>
                <p style="margin-top:8px;"><strong>Design:</strong> 課題ベース＋安静時の縦断収集、侵襲/非侵襲データの比較</p>
            </div>

            <div class="sidebar-box">
                <h4>Focus Areas</h4>
                <ul>
                    <li>脳活動の計測（EEG, fMRI, BCI）</li>
                    <li>神経科学研究</li>
                    <li>計算論的アプローチ</li>
                    <li>倫理と哲学</li>
                </ul>
            </div>

            <div class="sidebar-box">
                <h4>Ethics & Governance</h4>
                <ul>
                    <li>MIND Act of 2025 (US Federal) 準拠の検討</li>
                    <li>Neurorights議論（精神的プライバシー、認知的自由）<sup><a href="#ref-27">[27]</a></sup></li>
                    <li>デジタル相続・遺産管理の法的フレームワーク設計</li>
                    <li>本人性維持のための「情報の構造保存率」義務化</li>
                </ul>
            </div>

            <div class="sidebar-box">
                <h4>Data Standards</h4>
                <ul>
                    <li>BIDS-EEG標準への準拠（<strong>課題:</strong> Events.tsv, electrodes.tsv等のメタデータ拡充が急務）</li>
                    <li>メタデータ自動QAパイプライン</li>
                    <li>多施設間相互運用性の確保</li>
                </ul>
            </div>

            <div class="cta-box">
                <h4>Contribute</h4>
                <p>このプロジェクトに参加しませんか？</p>
                <a href="https://github.com/yasufumi-nakata/eegflow/issues" target="_blank">Issue を立てる</a>
            </div>

        </aside>
    </main>

    <footer>
        <p>Mind Uploading Research · <a href="https://github.com/yasufumi-nakata/eegflow">GitHub</a></p>
    </footer>

</body>

</html>
