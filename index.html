<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mind Uploading Research | マインドアップロード実現への道</title>
    <meta name="description" content="マインドアップロード実現のための中核となるコアサイト。意識や記憶の交換・複製を可能とする技術の研究とコミュニティの中心的ハブ。">
    <meta property="og:title" content="EEGFlow | マインドアップロード実現への道">
    <meta property="og:description" content="マインドアップロード実現のための中核となるコアサイト。意識や記憶の交換・複製を可能とする技術の研究とコミュニティの中心的ハブ。">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://eegflow.jp">
    <meta property="og:image" content="https://eegflow.jp/ogp.jpg">
    <meta name="twitter:card" content="summary_large_image">
    <link rel="icon"
        href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🧠</text></svg>">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&family=Source+Sans+3:wght@400;600;700&display=swap"
        rel="stylesheet">
    <style>
        :root {
            --font-serif: 'Libre Baskerville', 'Times New Roman', serif;
            --font-sans: 'Source Sans 3', 'Helvetica Neue', sans-serif;
            --color-bg: #0d0d0f;
            --color-paper: #161618;
            --color-text: #e8e8ec;
            --color-text-secondary: #a8a8b0;
            --color-text-muted: #6a6a75;
            --color-accent: #ef5350;
            --color-accent-dark: #c62828;
            --color-link: #64b5f6;
            --color-border: #2a2a30;
            --color-sidebar: #1a1a1e;
            --max-width: 1100px;
            --column-gap: 40px;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: var(--font-serif);
            font-size: 16px;
            line-height: 1.75;
            color: var(--color-text);
            background: var(--color-bg);
        }

        /* Header Bar */
        .journal-header {
            background: var(--color-accent);
            color: white;
            padding: 8px 20px;
            font-family: var(--font-sans);
            font-size: 12px;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .journal-header a {
            color: white;
            text-decoration: none;
        }

        .journal-header a:hover {
            text-decoration: underline;
        }

        /* Title Section */
        .article-header {
            max-width: var(--max-width);
            margin: 0 auto;
            padding: 40px 20px 30px;
            border-bottom: 2px solid var(--color-text);
        }

        .article-type {
            font-family: var(--font-sans);
            font-size: 12px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.15em;
            color: var(--color-accent);
            margin-bottom: 12px;
        }

        .article-title {
            font-size: 32px;
            font-weight: 700;
            line-height: 1.25;
            margin-bottom: 16px;
            color: var(--color-text);
        }

        .article-subtitle {
            font-size: 18px;
            font-style: italic;
            color: var(--color-text-secondary);
            margin-bottom: 20px;
        }

        .author-info {
            font-family: var(--font-sans);
            font-size: 14px;
            color: var(--color-text-secondary);
            margin-bottom: 8px;
        }

        .author-name {
            font-weight: 600;
            color: var(--color-text);
        }

        .article-meta {
            font-family: var(--font-sans);
            font-size: 12px;
            color: var(--color-text-muted);
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
            margin-top: 12px;
        }

        /* Main Layout */
        .main-container {
            max-width: var(--max-width);
            margin: 0 auto;
            display: grid;
            grid-template-columns: 1fr 280px;
            gap: var(--column-gap);
            padding: 30px 20px;
        }

        .content-column {
            min-width: 0;
        }

        .sidebar-column {
            font-family: var(--font-sans);
        }

        /* Content Styles */
        .section {
            margin-bottom: 30px;
        }

        .section-title {
            font-family: var(--font-sans);
            font-size: 13px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            color: var(--color-accent);
            margin-bottom: 12px;
            padding-bottom: 6px;
            border-bottom: 1px solid var(--color-border);
        }

        .section h3 {
            font-size: 18px;
            font-weight: 700;
            margin: 20px 0 10px;
            color: var(--color-text);
        }

        .section p {
            margin-bottom: 12px;
            text-align: justify;
        }

        /* Abstract Box */
        .abstract-box {
            background: var(--color-paper);
            border-left: 4px solid var(--color-accent);
            padding: 20px 24px;
            margin-bottom: 30px;
        }

        .abstract-box h2 {
            font-family: var(--font-sans);
            font-size: 12px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            color: var(--color-accent);
            margin-bottom: 10px;
        }

        .abstract-box p {
            font-size: 15px;
            line-height: 1.7;
            color: var(--color-text-secondary);
        }

        /* Key Points / Highlights */
        .key-points {
            background: var(--color-sidebar);
            padding: 20px;
            margin-bottom: 24px;
            border-radius: 4px;
        }

        .key-points h4 {
            font-size: 12px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.08em;
            color: var(--color-accent);
            margin-bottom: 12px;
        }

        .key-points ul {
            list-style: none;
            padding: 0;
        }

        .key-points li {
            font-size: 13px;
            line-height: 1.6;
            padding: 6px 0;
            padding-left: 16px;
            position: relative;
            border-bottom: 1px solid var(--color-border);
        }

        .key-points li:last-child {
            border-bottom: none;
        }

        .key-points li::before {
            content: '▸';
            position: absolute;
            left: 0;
            color: var(--color-accent);
            font-size: 10px;
        }

        /* Figure Box */
        .figure-box {
            background: var(--color-paper);
            padding: 16px;
            margin: 24px 0;
            border: 1px solid var(--color-border);
        }

        .figure-box .figure-content {
            background: white;
            padding: 20px;
            text-align: center;
            margin-bottom: 12px;
        }

        .figure-box .figure-label {
            font-family: var(--font-sans);
            font-size: 11px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--color-text);
            margin-bottom: 6px;
        }

        .figure-box .figure-caption {
            font-family: var(--font-sans);
            font-size: 12px;
            color: var(--color-text-secondary);
            text-align: left;
            line-height: 1.5;
        }

        /* Timeline/Progress Figure */
        .timeline-visual {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            padding: 10px 0;
            position: relative;
        }

        .timeline-visual::before {
            content: '';
            position: absolute;
            top: 28px;
            left: 40px;
            right: 40px;
            height: 2px;
            background: linear-gradient(to right, var(--color-accent), var(--color-border));
        }

        .timeline-item {
            text-align: center;
            flex: 1;
            position: relative;
            z-index: 1;
        }

        .timeline-dot {
            width: 16px;
            height: 16px;
            border-radius: 50%;
            background: var(--color-border);
            border: 2px solid white;
            margin: 20px auto 10px;
        }

        .timeline-dot.done {
            background: var(--color-accent);
        }

        .timeline-dot.current {
            background: white;
            border: 2px solid var(--color-accent);
            box-shadow: 0 0 0 3px rgba(183, 28, 28, 0.2);
        }

        .timeline-label {
            font-family: var(--font-sans);
            font-size: 11px;
            color: var(--color-text-secondary);
            line-height: 1.4;
        }

        /* Stage Cards */
        .stage-list {
            counter-reset: stage;
        }

        .stage-item {
            display: flex;
            gap: 16px;
            padding: 16px 0;
            border-bottom: 1px solid var(--color-border);
        }

        .stage-item:last-child {
            border-bottom: none;
        }

        .stage-number {
            counter-increment: stage;
            font-family: var(--font-sans);
            font-size: 24px;
            font-weight: 700;
            color: var(--color-accent);
            min-width: 40px;
        }

        .stage-number::before {
            content: counter(stage);
        }

        .stage-body h4 {
            font-family: var(--font-sans);
            font-size: 14px;
            font-weight: 700;
            margin-bottom: 6px;
            color: var(--color-text);
        }

        .stage-body p {
            font-size: 14px;
            line-height: 1.6;
            margin-bottom: 8px;
        }

        .tag-list {
            display: flex;
            flex-wrap: wrap;
            gap: 6px;
        }

        .tag {
            font-family: var(--font-sans);
            font-size: 10px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            padding: 3px 8px;
            background: var(--color-paper);
            border: 1px solid var(--color-border);
            color: var(--color-text-secondary);
        }

        /* Table Styles */
        .data-table {
            width: 100%;
            border-collapse: collapse;
            font-family: var(--font-sans);
            font-size: 13px;
            margin: 16px 0;
        }

        .data-table th {
            background: var(--color-paper);
            font-weight: 700;
            text-align: left;
            padding: 10px 12px;
            border-bottom: 2px solid var(--color-text);
            font-size: 11px;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }

        .data-table td {
            padding: 10px 12px;
            border-bottom: 1px solid var(--color-border);
            vertical-align: top;
        }

        .data-table td:first-child {
            font-weight: 700;
            color: var(--color-accent);
            white-space: nowrap;
        }

        /* Sidebar Styles */
        .sidebar-box {
            background: var(--color-sidebar);
            padding: 16px;
            margin-bottom: 20px;
            border-radius: 4px;
        }

        .sidebar-box h4 {
            font-size: 11px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.08em;
            color: var(--color-accent);
            margin-bottom: 12px;
            padding-bottom: 8px;
            border-bottom: 1px solid var(--color-border);
        }

        .sidebar-box p,
        .sidebar-box li {
            font-size: 12px;
            line-height: 1.6;
            color: var(--color-text-secondary);
        }

        .sidebar-box ul {
            list-style: none;
            padding: 0;
        }

        .sidebar-box li {
            padding: 4px 0;
            padding-left: 12px;
            position: relative;
        }

        .sidebar-box li::before {
            content: '•';
            position: absolute;
            left: 0;
            color: var(--color-accent);
        }

        /* Links */
        a {
            color: var(--color-link);
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        sup a {
            font-size: 11px;
            vertical-align: super;
        }

        /* Call to Action */
        .cta-box {
            background: var(--color-accent);
            color: white;
            padding: 20px;
            text-align: center;
            margin: 24px 0;
        }

        .cta-box h4 {
            font-family: var(--font-sans);
            font-size: 14px;
            font-weight: 700;
            margin-bottom: 8px;
        }

        .cta-box p {
            font-size: 13px;
            margin-bottom: 12px;
            opacity: 0.9;
        }

        .cta-box a {
            display: inline-block;
            font-family: var(--font-sans);
            font-size: 12px;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            padding: 10px 24px;
            background: white;
            color: var(--color-accent);
            text-decoration: none;
            transition: all 0.2s;
        }

        .cta-box a:hover {
            background: var(--color-paper);
            text-decoration: none;
        }

        /* References Section */
        .references {
            font-size: 12px;
            line-height: 1.7;
        }

        .references ol {
            padding-left: 24px;
        }

        .references li {
            margin-bottom: 8px;
            color: var(--color-text-secondary);
        }

        .references em,
        .references i {
            font-style: italic;
            color: var(--color-text);
        }

        /* Footer */
        footer {
            background: var(--color-text);
            color: white;
            padding: 24px 20px;
            font-family: var(--font-sans);
            font-size: 12px;
            text-align: center;
        }

        footer a {
            color: white;
            text-decoration: underline;
        }

        /* Note Box */
        .note-box {
            background: #2a2518;
            border-left: 3px solid #ffc107;
            padding: 12px 16px;
            margin: 16px 0;
            font-size: 14px;
        }

        .note-box strong {
            font-family: var(--font-sans);
            font-size: 12px;
            text-transform: uppercase;
            color: #ffca28;
        }

        /* Question Box */
        .question-box {
            border: 1px solid var(--color-border);
            padding: 16px;
            margin: 12px 0;
        }

        .question-box h4 {
            font-family: var(--font-sans);
            font-size: 14px;
            font-weight: 700;
            margin-bottom: 8px;
            color: var(--color-text);
        }

        .question-box p {
            font-size: 14px;
            color: var(--color-text-secondary);
            margin: 0;
        }

        .resolution-box {
            border: 1px solid #2f3b2f;
            background: #182018;
            padding: 14px 16px;
            margin-top: 10px;
            border-left: 3px solid #7cb342;
        }

        .resolution-box h5 {
            font-family: var(--font-sans);
            font-size: 13px;
            font-weight: 700;
            color: #c5e1a5;
            margin-bottom: 6px;
        }

        .resolution-box p {
            font-size: 13px;
            color: #d7e2cf;
            margin: 0;
            line-height: 1.5;
        }

        /* Responsive */
        @media (max-width: 900px) {
            .main-container {
                grid-template-columns: 1fr;
            }

            .sidebar-column {
                order: -1;
                display: grid;
                grid-template-columns: 1fr 1fr;
                gap: 16px;
            }
        }

        @media (max-width: 600px) {
            .article-title {
                font-size: 24px;
            }

            .sidebar-column {
                grid-template-columns: 1fr;
            }

            .timeline-visual {
                flex-direction: column;
                gap: 16px;
                align-items: flex-start;
            }

            .timeline-visual::before {
                display: none;
            }

            .timeline-item {
                display: flex;
                align-items: center;
                gap: 12px;
                text-align: left;
            }

            .timeline-dot {
                margin: 0;
            }
        }
    </style>
</head>

<body>

    <!-- Journal Header -->
    <header class="journal-header">
        <span>Mind Uploading Research Notes</span>
        <a href="https://github.com/yasufumi-nakata/eegflow" target="_blank">GitHub Repository →</a>
    </header>

    <!-- Article Header -->
    <header class="article-header">
        <p class="article-type">Perspective</p>
        <h1 class="article-title">マインドアップロード実現への道：技術・理論・倫理の統合アプローチ</h1>
        <p class="article-subtitle">脳の情報処理を別の基盤で再現し、心的機能を移植・複製するという研究仮説の現状と展望</p>
        <p class="author-info">
            <span class="author-name">Mind Uploading Research Project</span>
        </p>
        <div class="article-meta">
            <span>Open Access</span>
            <span>Last Updated: 2026-01-15</span>
            <span>研究ノート (2026年1月改訂)</span>
        </div>
    </header>

    <!-- Main Content -->
    <main class="main-container">
        <article class="content-column">

            <!-- Abstract -->
            <div class="abstract-box">
                <h2>Abstract</h2>
                <p>マインドアップロード（Whole Brain Emulation, WBE）は、脳の情報処理とそれに伴う心的機能を、生物学的基盤から計算機等の別基盤へ移植・再現する研究領域である<sup><a
                            href="#ref-2">[2]</a></sup>。本稿ではこの壮大な課題を、(1)計測、(2)解読、(3)実装の3段階の技術的フレームワークで整理し、各段階における最新の学術的知見と未解決の課題を批判的に検討する。特に、意識の統合情報理論（IIT
                    4.0）<sup><a href="#ref-17">[17]</a></sup>やNTTによるMind Captioning技術<sup><a
                            href="#ref-11">[11]</a></sup>といった最新トピックを、その理論的・技術的限界と共に論じる。IITが直面する計算量の問題や反証可能性に関する批判<sup><a
                            href="#ref-1">[1]</a></sup>、デコーディング技術とエミュレーションの間の論理的飛躍など、楽観的な技術論では見過ごされがちな課題を直視し、より厳密で実現可能な研究計画を提案する。本稿は、これらの技術的・理論的課題に加え、デレク・パーフィットの心理的連続性理論<sup><a
                            href="#ref-4">[4]</a></sup>に端を発する哲学的問題や、MIND Act of 2025<sup><a
                            href="#ref-24">[24]</a></sup>に代表される法的・倫理的課題を統合的に概観し、今後の研究の方向性を提示する。</p>
            </div>

            <!-- Introduction -->
            <section class="section">
                <h2 class="section-title">Introduction: Theoretical Foundations Revisited</h2>

                <h3>1.1. 意識の科学：理論的基盤の再検討</h3>
                <p>マインドアップロード（WBE）が再現すべき「意識」とは何か。この問いに答えるため、本プロジェクトは複数の主要な意識理論を批判的に統合し、その実装に向けた具体的な設計指針を導出する。従来、我々は<strong>統合情報理論（IIT）</strong>と<strong>心理的連続性理論</strong>を理論的支柱としてきたが、最新の学術的動向、特にIITと競合する<strong>グローバル神経ワークスペース理論（GNWT）</strong><sup><a
                            href="#ref-43">[43]</a></sup>との対立と統合に関する議論を踏まえ、フレームワークをアップデートする。</p>

                <div class="question-box">
                    <h4>中心的課題: 意識の座はどこか？</h4>
                    <p>IITは意識の物理的基盤（PCC, Posterior Cortical Hot
                        Zone）を後頭葉中心の因果構造に求めるのに対し、GNWTは意識的アクセスには前頭前野を含む広範なネットワークによる「グローバルな情報放送」が不可欠だと主張する。この対立は、WBEにおいてどの脳領域の結合性を優先的にエミュレートすべきかという、リソース配分の根幹に関わる問題である。
                    </p>
                    <div class="resolution-box">
                        <h5>解決の方向性: Adversarial Collaborationと理論の相補的統合</h5>
                        <p>2023年に提案された「Adversarial Collaboration」プロトコル<sup><a
                                    href="#ref-42">[42]</a></sup>や、その枠組みに沿った理論検証の報告<sup><a
                                    href="#ref-54">[54]</a></sup>は、意識理論を「口頭の多数派争い」から、事前登録された予測に基づく共同検証へ移す流れを加速させた。本サイトではこの潮流を踏まえ、両理論を排他的なものではなく、意識の異なる側面を捉える<strong>相補的なプロセス</strong>として位置づける。すなわち、IITが示す「情報の統合（qualiaの生成）」と、GNWTが示す「情報のグローバルな利用可能性（意識的報告）」は、一つのシステムが両立しうる機能である。WBEの評価指標には、両理論に基づく予測（例：統合情報量Φと、広域ネットワークの活動）を組み込み、多角的な検証を行う。
                        </p>
                    </div>
                </div>

                <h3>1.2. 理論から実装へ：技術的・哲学的課題</h3>
                <p><strong>IITのデジタル基盤への移植課題：</strong> IIT 4.0<sup><a
                            href="#ref-17">[17]</a></sup>をWBEに応用するには、その公理系をデジタル基盤上でいかに満たすかという問題が残る。特に、物理的な実在を問う「内因的実在（Intrinsic
                    Existence）」の公理<sup><a
                            href="#ref-44">[44]</a></sup>は、離散的な計算システムにおいて自明ではない。本プロジェクトでは、デジタルエミュレーションにおける状態遷移が、元の脳の因果構造（Φ）を数学的に保存するための条件（例：時間的・空間的サンプリングレートの制約）を明記し、その近似の度合いを定量化することを技術目標とする。同時に、IITが直面する「Unfolding
                    Argument」<sup><a href="#ref-40">[40]</a></sup>や計算量の爆発といった根源的な課題も依然として重要であり、IITを絶対的な指標と見なすことはできない。
                </p>

                <p><strong>心理的連続性とコピー問題：</strong> デレク・パーフィットの心理的連続性理論<sup><a
                            href="#ref-4">[4]</a></sup>は、記憶や性格の連続性を本人性の根拠とする。これは、単なる静的なデータコピーではなく、「動的なプロセス」の維持をWBEに要求する。この理論が提起する「コピー問題（分身のパラドックス）」に対し、我々は「段階的な神経置換」や「ハイブリッド脳システム」といった思考実験を、検証可能な工学的プロトコルへと落とし込むことを目指す。
                </p>
                <p><strong>プロセス哲学への転回：</strong>
                    意識を静的な「モノ」ではなく、環境との相互作用の中で絶えず更新される「プロセス」として捉える視点は、Whiteheadの哲学やFristonの自由エネルギー原理とも共鳴する。本プロジェクトは、この動的な実在性を計算機上で維持するための技術的要件（例：Slow
                    Continuous Mind Uploading）を具体化する。</p>
                <div class="note-box">
                    <strong>研究としての約束</strong>
                    <p>以下を「最低限のガードレール」として運用する：主要な主張には一次/総説などの出典を付す・仮説と事実、価値判断を区別し不確実性を併記する・評価指標や手順を先に定義し再現可能性を優先する。</p>
                </div>
            </section>


            <!-- Technical Framework -->
            <section class="section">
                <h2 class="section-title">Technical Framework</h2>

                <p>マインドアップロードの実現に向けた技術的ロードマップは、「計測」「解読」「実装」の3段階で構想される。</p>

                <div class="stage-list">
                    <div class="stage-item">
                        <div class="stage-number"></div>
                        <div class="stage-body">
                            <h4>1. 計測（Sensing）：脳活動の精密な読み取り</h4>
                            <p>高時間分解能を持つ脳波（EEG）は依然としてWBEの有力な入力信号ですが、その空間分解能の低さは根本的な課題です。脳波源推定（ESI）は、この課題を解決する計算論的アプローチですが、これは本質的に解が一意に定まらない**不良設定問題（ill-posed
                                problem）**です<sup><a href="#ref-5">[5]</a></sup>。ESIの結果を盲信することは、学術的厳密性を著しく損ないます。</p>
                            <p>この問題に対処するため、本プロジェクトでは以下の技術的要件を**必須プロトコル**として定義します。</p>
                            <ul
                                style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px; line-height: 1.6;">
                                <li style="margin-bottom: 8px;">
                                    <strong>ハードウェア要件の厳格化：</strong>最低でも<strong>128チャンネル以上の高密度脳波計（HD-EEG）</strong>の使用を必須とし、信号の空間的サンプリングレートを最大化します。
                                </li>
                                <li style="margin-bottom: 8px;">
                                    <strong>個別化頭部モデル（IHM）の必須化：</strong>汎用的な頭部モデルではなく、各個人のMRIスキャンから生成された忠実な頭部モデルを用いることで、信号伝達の物理シミュレーション精度を保証します。
                                </li>
                                <li style="margin-bottom: 8px;">
                                    <strong>性能ベンチマークの導入：</strong>シミュレーションデータを用いて、推定アルゴリズムの**Source Localization Error
                                    (SLE) が許容限界（例: 10mm未満）**に収まることを検証するプロセスを義務付けます。
                                </li>
                                <li style="margin-bottom: 8px;">
                                    <strong>不確実性の定量化と可視化：</strong>点推定（最も可能性の高い単一の解）のみを報告するのではなく、<strong>ベイズ推定に基づく事後確率分布</strong>を計算し、推定結果の空間的な不確かさを常に可視化・定量化します。これは`eegflow/02_source_imaging.py`に実装されるべき中心機能です。
                                </li>
                            </ul>
                            <div class="tag-list" style="margin-top: 12px;">
                                <span class="tag">HD-EEG (128ch+)</span>
                                <span class="tag">ESI (Source Imaging)</span>
                                <span class="tag">個別化頭部モデル (IHM)</span>
                                <span class="tag">ベイズ推定</span>
                            </div>
                        </div>
                    </div>
                    <div class="stage-item">
                        <div class="stage-number"></div>
                        <div class="stage-body">
                            <h4>2. 解読（Decoding）：受動的相関から能動的生成へ</h4>
                            <p>脳活動から心的内容を「読み出す」従来のデコーディング研究（例：Mind Captioning<sup><a
                                        href="#ref-11">[11]</a></sup>）は、脳を**受動的な入力-出力装置**として扱います。しかし、生物学的な脳は、環境を予測し、その予測誤差を最小化するように行動する**能動的推論（Active
                                Inference）**システムです<sup><a
                                        href="#ref-45">[45]</a></sup>。この原理（自由エネルギー原理）こそが、単なる情報処理装置ではない、自己組織化されたエージェントの振る舞いを説明します。
                            </p>
                            <p>WBEが単なる静的な「記録の再生」ではなく、環境と相互作用する「動的な意識体」として機能するためには、この能動的推論のプロセスを再現することが不可欠です。そこで、本プロジェクトは以下の設計転換を行います。
                            </p>
                            <ul
                                style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px; line-height: 1.6;">
                                <li style="margin-bottom: 8px;">
                                    <strong>マルコフブランケットの設計：</strong>エミュレートされたシステムが、外界からの感覚入力（Sensory
                                    states）と外界への行動出力（Active
                                    states）を区別するためのインターフェース、すなわち**「マルコフブランケット」**を明確に設計します。これがデジタル意識の身体的境界となります<sup><a
                                            href="#ref-46">[46]</a></sup>。
                                </li>
                                <li style="margin-bottom: 8px;">
                                    <strong>生成モデルとしての脳の再現：</strong>`03_causal_modeling.py`で用いられる<strong>動的因果モデリング（DCM）</strong><sup><a
                                            href="#ref-13">[13]</a></sup>を拡張し、単なる有効結合性の推定に留めず、外界に関する信念を更新し行動を決定する**生成モデル（Generative
                                    Model）**のパラメータを同定する枠組みへと昇華させます。
                                </li>
                            </ul>
                            <div class="tag-list" style="margin-top: 12px;">
                                <span class="tag">Active Inference</span>
                                <span class="tag">Free Energy Principle</span>
                                <span class="tag">Markov Blanket</span>
                                <span class="tag">Generative Model (DCM)</span>
                            </div>
                        </div>
                    </div>
                    <div class="stage-item">
                        <div class="stage-number"></div>
                        <div class="stage-body">
                            <h4>3. 実装（Implementation）：段階的置換と本人性の保存</h4>
                            <p>「スキャン＆コピー」方式が抱える「多重性の異議（Multiplicity Objection）」<sup><a
                                        href="#ref-58">[58]</a></sup>を回避するため、本プロジェクトは<strong>「Slow Continuous Mind
                                    Uploading（ゆっくりとした連続的アップロード）」</strong><sup><a
                                        href="#ref-59">[59]</a></sup>を採用します。これは、生物学的脳の一部をBCIを介して人工ニューラルネットワークに段階的に置換し、意識の連続性を保ちながら移行する手法です。
                            </p>
                            <p>このプロセスにおける本人性検証は、以下の指標によって評価されます。</p>
                            <ul
                                style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px; line-height: 1.6;">
                                <li style="margin-bottom: 8px;">
                                    <strong>予測誤差最小化の効率性：</strong>エミュレーションが、予期せぬ感覚入力に対して、元の脳と同様の効率で予測誤差を最小化（＝驚きを抑制）できるか。
                                </li>
                                <li style="margin-bottom: 8px;">
                                    <strong>生成的モデルの類似性：</strong>DCM等を通じて同定された「元の脳」と「エミュレーション」の生成モデルが、統計的にどの程度類似しているか。
                                </li>
                            </ul>
                            <p>このアプローチは、意識を静的なパターンとしてコピーするのではなく、自己を維持し続ける生命的なプロセスとして「移行」させることを目指す、本プロジェクトの核心的理念です。</p>
                            <div class="tag-list" style="margin-top: 12px;">
                                <span class="tag">Psychological Continuity</span>
                                <span class="tag">Process Dynamics</span>
                                <span class="tag">Predictive Coding</span>
                                <span class="tag">本人性ベンチマーク</span>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Reproducibility -->
            <section class="section">
                <h2 class="section-title">プロジェクトの実体性と再現性 (Substance and Reproducibility)</h2>
                <p>「EEGFlow」というプロジェクト名が示す通り、本研究は計算論的手法に基づいている。しかし、現状のGitHubリポジトリにはウェブサイト関連ファイルしか存在せず、研究プロジェクトとしての実体性・再現性が欠如しているとの批判は免れない。この重大な懸念に応えるため、今後は以下の要素を段階的にリポジトリに追加し、ウェブサイトの主張を裏付けるコードベースを構築する。
                </p>
                <ul style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px; line-height: 1.6;">
                    <li style="margin-bottom: 8px;">
                        <strong>データ処理パイプライン：</strong>BIDS準拠の生データから、ESI、DCM解析に至るまでの最小限実行可能な処理スクリプト（Python/MNE-Python,
                        SPM, FieldTrip等のラッパー）を公開する。
                    </li>
                    <li style="margin-bottom: 8px;"><strong>デコーディングモデル：</strong>Mind
                        Captioningに類するTransformerベースのモデルアーキテクチャ定義と、ダミーデータを用いた学習・推論コードを公開する。</li>
                    <li style="margin-bottom: 8px;">
                        <strong>データスキーマの拡充：</strong>`dataset_description.json`に加え、EEGデータの具体的な構造（例：`sub-01/eeg/sub-01_task-rest_eeg.eeg`）や、計測プロトコルを記述した`eeg.json`のスキーマ例を公開し、BIDS標準の形式的遵守から実質的遵守へと移行する。
                    </li>
                </ul>
            </section>

            <!-- Current Status -->
            <section class="section">
                <h2 class="section-title">主要な技術的課題 (Key Technical Challenges)</h2>

                <h3>コネクトームとダイナミクスのギャップ</h3>
                <p>図1が示す構造的コネクトーム（神経配線図）の研究は大きく進展しているが、それだけでは脳の動的な活動を説明するには不十分である。脳機能は、主に2つの理由から、静的な配線図以上のものを要求する。第一に、脳の機能状態は、シナプス結合だけでなく、ドーパミンやセロトニンといった神経修飾物質が脳全体に拡散して作用する「体積伝導（Volume
                    Transmission）」によっても大きく左右される<sup><a
                            href="#ref-39">[39]</a></sup>。第二に、これまで補助細胞と見なされてきた<strong>非神経細胞（特にアストロサイト）の役割が過小評価されている</strong>。近年の研究は、アストロサイトが神経伝達物質を感知・放出し、シナプス可塑性や情報処理の時定数を能動的に制御する「三者系シナプス（Tripartite
                    Synapse）」の不可欠な構成要素であることを示している<sup><a href="#ref-41">[41]</a></sup>。</p>
                <p>このことは、脳のエミュレーションが、単なるニューロンの接続性（コネクトーム）の再現に留まらず、神経修飾状態やグリア細胞による変調ダイナミクスといった、より複雑な動的要素を第一級のパラメータとして組み込む必要があることを意味する。この静的な構造と動的な状態の間のギャップを埋めるため、将来的には遺伝子発現情報から神経接続の特性を推定する「トランスクリプトーム・コネクトミクス」や、神経修飾状態をマッピングする動的な状態遷移モデルをフレームワークに統合する必要がある。
                </p>

                <!-- Figure: Connectome Progress -->
                <div class="figure-box">
                    <div class="figure-content">
                        <div class="timeline-visual">
                            <div class="timeline-item">
                                <div class="timeline-dot done"></div>
                                <div class="timeline-label">線虫<br><strong>302</strong> neurons</div>
                            </div>
                            <div class="timeline-item">
                                <div class="timeline-dot done"></div>
                                <div class="timeline-label">ショウジョウバエ<br><strong>~25,000</strong> neurons</div>
                            </div>
                            <div class="timeline-item">
                                <div class="timeline-dot current"></div>
                                <div class="timeline-label">マウス<br><strong>~71M</strong> neurons</div>
                            </div>
                            <div class="timeline-item">
                                <div class="timeline-dot"></div>
                                <div class="timeline-label">ヒト<br><strong>~86B</strong> neurons</div>
                            </div>
                        </div>
                    </div>
                    <p class="figure-label">Figure 1</p>
                    <p class="figure-caption">コネクトーム研究の進展とスケール。線虫（<em>C.
                            elegans</em>）やショウジョウバエでは完全な構造的コネクトームが解明されているが、機能的ダイナミクスの解明は依然課題である。マウスのニューロン数は約7100万であり、コネクトーム解析は現在進行中である。ヒト脳は約860億ニューロンを有する<sup><a
                                href="#ref-57">[57]</a></sup>。
                    </p>
                </div>
            </section>

            <!-- Research Program -->
            <section class="section">
                <h2 class="section-title">Research Program</h2>

                <p>論文化を意識した実証プランでは、計測・解読・実装の各段階を統合的に示す。目標はマルチモーダル計測と神経解読を統合した「本人性維持」評価系の設計と論文化である。加えて、計測段階の柱として、EEGを中心とした<strong>行動非依存の意識指標</strong>（複雑性×摂動応答×臨界性）のロードマップも明示する。
                </p>

                <!-- Table: Roadmap -->
                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Phase</th>
                            <th>計測/データ</th>
                            <th>解読/解析</th>
                            <th>実装/倫理</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>1</td>
                            <td>HD-EEG/fMRI同時計測セットアップ、再現性データ収集。IHM採用とBIDSメタデータ拡充。</td>
                            <td>Transformerベースのデコーディングに加え、LLM由来ノイズを定量化する「因果的整合性チェック」プロトコルの導入。</td>
                            <td>MIND Act 2025準拠の同意プロセス、神経データプライバシー保護設計。</td>
                        </tr>
                        <tr>
                            <td>2</td>
                            <td>ESI信号分離とMEGデータの融合。逆問題制約条件の妥当性検証。</td>
                            <td>Dynamic Causal Modeling (DCM) による部位間因果ダイナミクス解析と生成モデルの同定。</td>
                            <td>心理的連続性理論に基づく「本人性」評価指標の操作的定義と、コピー問題への工学的アプローチの検討。</td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td>WBA統合フレームワークでの動作検証。非神経細胞（グリア）のモデル化。</td>
                            <td>DCMを用いた「元の脳」と「エミュレーション」の有効連結性比較による本人性検証。</td>
                            <td>Neurorightsに基づく権利枠組み、デジタル遺産・継承権の法的整備。</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <!-- LLM Research Update -->
            <section class="section" id="llm-research-update">
                <h2 class="section-title">LLM研究アップデート：脳解読における「言語事前分布」との付き合い方</h2>
                <p>Mind Captioningのようなbrain-to-text系の解読では、Transformer/LLMが「自然な文章」を強力に補完する一方で、脳信号の根拠が薄いときにもっともらしい幻覚（hallucination）を混入させる危険もある<sup><a
                            href="#ref-60">[60]</a></sup>。本プロジェクトで表現している「LLM由来ノイズ」は、この<strong>言語事前分布が勝ってしまう成分</strong>として捉え、実験・解析・評価の三点セットで切り分ける必要がある。</p>

                <h3>近年のLLM研究（実装に効く要点）</h3>
                <ul style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px; line-height: 1.6;">
                    <li style="margin-bottom: 8px;"><strong>嗜好整合（指示追従）学習：</strong>RLHF/Instruction tuningで出力方針が変わるため、被験者間比較や縦断研究では「モデル/方針の固定」と「変更の記録」が重要になる<sup><a
                                href="#ref-61">[61]</a></sup>。学習を必要最小限にする場合はDPO系の選択肢もある<sup><a href="#ref-62">[62]</a></sup>。</li>
                    <li style="margin-bottom: 8px;"><strong>軽量な個人適応：</strong>被験者固有の語彙・記憶・文体に合わせる際、PEFT/量子化微調整（QLoRA等）で計算コストを抑えつつ適応できる<sup><a href="#ref-63">[63]</a></sup>。</li>
                    <li style="margin-bottom: 8px;"><strong>根拠付き生成（Grounding）：</strong>RAGにより、生成を外部コーパスに“接地”させ、根拠（参照元）をログとして残せる<sup><a href="#ref-64">[64]</a></sup>。</li>
                    <li style="margin-bottom: 8px;"><strong>ツール利用とエージェント化：</strong>推論と行為（検索・計算・操作）を分離し、どの外部情報が出力に影響したかを追跡可能にする枠組みが整ってきた<sup><a
                                href="#ref-65">[65]</a></sup><sup><a href="#ref-66">[66]</a></sup>。</li>
                    <li style="margin-bottom: 8px;"><strong>幻覚の検出：</strong>ブラックボックスでも自己一致性から幻覚を検出する系（SelfCheckGPT等）が提案されている<sup><a href="#ref-67">[67]</a></sup>。</li>
                </ul>

                <h3>EEGFlow側での「因果的整合性チェック」への落とし込み</h3>
                <ul style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px; line-height: 1.6;">
                    <li style="margin-bottom: 8px;"><strong>LLM由来ノイズの基準線：</strong>脳信号シャッフル／試行入れ替え等の反事実入力で出力分布を推定し、「言語事前分布だけで出る文章」をベースライン化する。</li>
                    <li style="margin-bottom: 8px;"><strong>不確実性と棄権（abstention）：</strong>根拠が弱いときに無理に“それっぽい文”を出さない設計（低信頼時は要再計測/要追試として扱う）を先に決める。</li>
                    <li style="margin-bottom: 8px;"><strong>再現性ログ：</strong>モデル名/重み版、デコード温度、プロンプト、RAGコーパス、ツール呼び出しログを固定・保存して「同じ入力で同じ結論になる」状態を担保する。</li>
                </ul>

                <div class="tag-list" style="margin-top: 12px;">
                    <span class="tag">LLM</span>
                    <span class="tag">RAG</span>
                    <span class="tag">DPO</span>
                    <span class="tag">QLoRA</span>
                    <span class="tag">Hallucination</span>
                </div>
            </section>

            <!-- EEG Consciousness Roadmap -->
            <section class="section" id="eeg-consciousness-roadmap">
                <h2 class="section-title">EEGで意識を測る：複雑性×摂動応答×臨界性ロードマップ</h2>

                <p>マインドアップロードの「計測」段階は、単に神経信号を高密度に取得するだけでは完結しない。意識レベルや意識内容に関わる情報処理を、<strong>行動報告に依存せず</strong>に定量化し、条件差・個体差・装置差を越えて再現できる「ものさし」へ落とす必要がある。これはWBEの評価（アップロード後に意識が保たれているか）にも直結する。
                </p>

                <div class="note-box">
                    <strong>Design Goal</strong><br>
                    行動（報告）に依存しない指標、report confoundの分離、摂動による因果、一般化可能性──この4点を満たす評価系を、EEG中心に構築する。
                </div>

                <h3>強い結論に近づくための4要件</h3>
                <ol style="margin: 0; padding-left: 20px; font-size: 14px; line-height: 1.6;">
                    <li style="margin-bottom: 8px;">
                        <strong>行動（報告）に依存しない意識指標</strong>：感覚入力や応答が制限されても推定できる指標（例：摂動複雑性）<sup><a
                                href="#ref-47">[47]</a></sup>
                    </li>
                    <li style="margin-bottom: 8px;"><strong>report
                            confoundの切り分け</strong>：no-reportパラダイム等で、知覚そのものと「報告に必要な後段処理」を分離する<sup><a
                                href="#ref-48">[48]</a></sup></li>
                    <li style="margin-bottom: 8px;">
                        <strong>相関ではなく因果</strong>：摂動（TMS等）に対する応答伝播の崩れ／維持を介して、結合性の因果的読み出しを行う<sup><a
                                href="#ref-49">[49]</a></sup>
                    </li>
                    <li style="margin-bottom: 8px;"><strong>一般化（頑健性）</strong>：被験者・条件・装置をまたいでも成立するパイプラインと検証設計（再現性・外部データ）
                    </li>
                </ol>

                <h3>コア発想：I/O「揺らぎ」を計測可能な量へ</h3>
                <p>本サイトでは、意識を情報処理の「揺らぎ」と捉える直観を、査読耐性の高い定量指標へ接続するために、次の三つを中核に据える。</p>
                <ul style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px; line-height: 1.6;">
                    <li style="margin-bottom: 8px;"><strong>複雑性（complexity）</strong>：安静時EEGのLZ複雑性など、状態依存で変化する指標<sup><a
                                href="#ref-50">[50]</a></sup></li>
                    <li style="margin-bottom: 8px;"><strong>摂動応答の複雑性（perturbational
                            complexity）</strong>：刺激に対する状態遷移・次元圧縮に基づく指標（PCI/PCI-ST）<sup><a
                                href="#ref-47">[47]</a></sup><sup><a href="#ref-51">[51]</a></sup></li>
                    <li style="margin-bottom: 8px;">
                        <strong>臨界性（criticality）</strong>：脳活動が秩序と無秩序の境界、いわゆる「カオスの縁（edge-of-chaos）」に位置することで、複雑性と摂動感受性が最大化される力学状態。安静時EEGの臨界性指標が、意識レベルや意識能力を予測する強力な候補となっている<sup><a
                                href="#ref-52">[52]</a>, <a href="#ref-56">[56]</a></sup>。
                    </li>
                </ul>
                <p>この枠組みでは、I/Oは次のように読み替えられる：<strong>I（Input）＝摂動（刺激・介入）</strong>、<strong>O（Output）＝脳の複雑性応答</strong>、そしてその背景として<strong>臨界性</strong>を扱う。
                </p>

                <h3>研究の芯：2つの路線（A→Bの順で積む）</h3>
                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Route</th>
                            <th>狙い</th>
                            <th>強み</th>
                            <th>主な課題</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>A</td>
                            <td>ベッドサイド意識メータ（行動不能でも推定）</td>
                            <td>臨床価値が高く、評価指標（PCI/PCI-ST）の議論が組みやすい<sup><a href="#ref-47">[47]</a></sup><sup><a
                                        href="#ref-55">[55]</a></sup></td>
                            <td>摂動系（TMS等）の導入・安全性・運用コスト</td>
                        </tr>
                        <tr>
                            <td>B</td>
                            <td>臨界性からの統一説明（複雑性・摂動応答・伝播）</td>
                            <td>安静時EEGからの予測など、装置制約が小さい方向へ拡張できる<sup><a href="#ref-52">[52]</a></sup></td>
                            <td>交絡の統制と因果の取り方（介入設計）が難しい</td>
                        </tr>
                    </tbody>
                </table>

                <h3>ロードマップ（大学院を想定）</h3>
                <div class="stage-list">
                    <div class="stage-item">
                        <div class="stage-number"></div>
                        <div class="stage-body">
                            <h4>フェーズ0：基盤整備（〜1年）—「測れる」「再現できる」を固める</h4>
                            <p>EEG解析パイプラインを固定し、複雑性・臨界性・report confound分離を同一データ上で回せる状態にする。</p>
                            <ul
                                style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px; line-height: 1.6;">
                                <li style="margin-bottom: 8px;">前処理・アーチファクト除去・ログまで含む再現可能な解析（BIDS等）</li>
                                <li style="margin-bottom: 8px;">公開データで、麻酔/鎮静に伴う複雑性変化の再現<sup><a
                                            href="#ref-50">[50]</a></sup><sup><a href="#ref-53">[53]</a></sup></li>
                                <li style="margin-bottom: 8px;">no-report設計（瞳孔/EOG/OKN等）を最初から組み込み<sup><a
                                            href="#ref-48">[48]</a></sup></li>
                                <li style="margin-bottom: 8px;">多モーダルI/O（EEG＋EOG/瞳孔＋ECG/PPG）までを現実的に統合</li>
                            </ul>
                            <div class="tag-list" style="margin-top: 12px;">
                                <span class="tag">Reproducible Pipeline</span>
                                <span class="tag">No-Report</span>
                                <span class="tag">LZ Complexity</span>
                                <span class="tag">Criticality</span>
                            </div>
                        </div>
                    </div>

                    <div class="stage-item">
                        <div class="stage-number"></div>
                        <div class="stage-body">
                            <h4>フェーズ1：摂動応答（1〜2年目相当）—「PCI/PCI-STライン」を握る</h4>
                            <p>摂動（TMSや感覚刺激等）に対する応答複雑性を中核指標として整備し、行動非依存の推定に接続する。</p>
                            <ul
                                style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px; line-height: 1.6;">
                                <li style="margin-bottom: 8px;">理想：TMS-EEGでPCI系指標を扱う<sup><a
                                            href="#ref-47">[47]</a></sup></li>
                                <li style="margin-bottom: 8px;">現実解：PCI-STの思想（刺激応答の状態遷移・次元圧縮）を他の摂動へ移植<sup><a
                                            href="#ref-51">[51]</a></sup></li>
                            </ul>
                            <div class="tag-list" style="margin-top: 12px;">
                                <span class="tag">Perturbation</span>
                                <span class="tag">PCI / PCI-ST</span>
                                <span class="tag">Causal Propagation</span>
                            </div>
                        </div>
                    </div>

                    <div class="stage-item">
                        <div class="stage-number"></div>
                        <div class="stage-body">
                            <h4>フェーズ2：安静時から推定（2〜3年目相当）—「摂動なし」へ拡張</h4>
                            <p>安静時EEGの力学指標（臨界性など）から、意識能力や摂動応答指標を予測する方向へ伸ばす。これにより、侵襲的な摂動なしでの意識評価、すなわち臨床での大規模スクリーニングの可能性が拓かれる。
                            </p>
                            <p style="margin-top: 8px;">
                                最新の研究は、この方向性を強く支持している。安静時EEGの臨界性指標は、プロポフォール等で意識を失うと低下する一方、意識を保ったまま幻覚作用を引き起こすケタミン麻酔では維持されることを示した。さらに、この安静時の指標が、侵襲的な刺激を必要とするPCIの値を予測できることも報告されており<sup><a
                                        href="#ref-52">[52]</a>, <a href="#ref-56">[56]</a></sup>、両アプローチを統一する理論的基盤となりうる。
                            </p>
                            <div class="tag-list" style="margin-top: 12px;">
                                <span class="tag">Resting-State EEG</span>
                                <span class="tag">Critical Dynamics</span>
                                <span class="tag">Bedside</span>
                            </div>
                        </div>
                    </div>

                    <div class="stage-item">
                        <div class="stage-number"></div>
                        <div class="stage-body">
                            <h4>フェーズ3：因果（3〜4年目相当）—「条件」であることを示す</h4>
                            <p>複雑性／臨界性／摂動応答が、単なる相関ではなく意識の条件であることを、介入または状態操作で押さえる。</p>
                            <ul
                                style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px; line-height: 1.6;">
                                <li style="margin-bottom: 8px;">介入で指標を動かし、意識関連アウトカムの変化と対応づける</li>
                                <li style="margin-bottom: 8px;">薬理・鎮静・麻酔など、状態変化に沿って系列を揃える<sup><a
                                            href="#ref-50">[50]</a></sup></li>
                            </ul>
                            <div class="tag-list" style="margin-top: 12px;">
                                <span class="tag">Causality</span>
                                <span class="tag">Intervention</span>
                                <span class="tag">Anesthesia</span>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="resolution-box">
                    <h5>直近1〜3か月のToDo（最小で効く順）</h5>
                    <ul
                        style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 13px; line-height: 1.5; color: #d7e2cf;">
                        <li style="margin-bottom: 6px;">解析パイプラインを固定（自動化・ログ・再現性）</li>
                        <li style="margin-bottom: 6px;">同一EEGで「複雑性＋臨界性」を計算し、再テスト信頼性を評価</li>
                        <li style="margin-bottom: 6px;">reportあり／なし条件を併走できる実験設計にする<sup><a href="#ref-48">[48]</a></sup>
                        </li>
                        <li style="margin-bottom: 6px;">公開データで、麻酔/鎮静に伴う変化を一度再現する<sup><a href="#ref-50">[50]</a></sup>
                        </li>
                        <li>摂動導入の可否に応じて、PCI/PCI-ST路線の技術調査と共同先探索<sup><a href="#ref-51">[51]</a></sup></li>
                    </ul>
                </div>

                <h3>理論的立ち位置と研究のインパクト</h3>
                <p>本ロードマップは、特定の意識理論（IIT,
                    GNWT等）の正しさを証明すること自体を目的としない。むしろ、それらの理論に「巻き込まれず、利用する」というプラグマティックな立ち位置をとる。すなわち、複雑性、摂動応答、臨界性といった<strong>測定可能な量</strong>を軸に研究を進め、各理論が提唱する仮説を検証するための「ものさし」を提供することを目指す。このアプローチは、近年の理論対立を共同検証によって解決しようとする学術的潮流とも合致する<sup><a
                            href="#ref-54">[54]</a></sup>。</p>
                <p>この研究の先に目指すのは、単一の論文に留まらない「ノーベル級のインパクト」を生み出す構造の設計である。具体的には、(1)臨床現場で利用可能な「世界標準の意識指標」を確立すること、(2)介入によって意識状態を操作し「相関から因果へ」と議論を深めること、そして(3)重症患者の診断支援など「臨床で実際に人を救う」こと、の3点を満たすことで、研究の価値を社会的に実証する。
                </p>
            </section>

            <!-- Legal and Ethical Framework -->
            <section class="section">
                <h2 class="section-title">法的・倫理的枠組みの具体化 (Legal & Ethical Specification)</h2>
                <p>本研究は技術開発と並行し、法的・倫理的課題の具体的な検討を不可分の一部と見なす。特に、以下の2つの論点を深く掘り下げる。</p>
                <h3>MIND Act 2025 と Neurorights の拡張</h3>
                <p>米国で提案された「MIND Act of 2025」<sup><a
                            href="#ref-24">[24]</a></sup>は神経データプライバシー保護の重要な一歩だが、その法的拘束力と適用範囲には注意が必要である。同法案は主に**「神経データのプライバシー保護」**に焦点を当てており、アップロードされた主体の「法的権利（人格権）」を直接定義するものではない。本プロジェクトでは、サイト内でプライバシーに偏重しているとの批判を真摯に受け止め、Ienca
                    & Andornoが提唱する「Neurorights」<sup><a
                            href="#ref-27">[27]</a></sup>の枠組みをより包括的に議論する。特に、認知的自由、精神的完全性、心理的連続性の権利が、デジタル化された意識にとっても保障されるべきだという前提に立ち、その具体的な保護法益を検討する。これは、単なるデータ保護を超え、アップロード後の存在の尊厳に関わる核心的な論点である。
                </p>
                <h3>デジタル人格権と国際人権との整合性</h3>
                <p>「デジタル自然人」という概念を導入するならば、それは既存の法体系との複雑な相互作用を生む。例えば、アップロードされた主体が財産を所有し、契約を結ぶ能力を持つ場合、それは法人格に近いのか、あるいは新たな権利主体と見なすべきか。オリジナルの人間が死亡した場合、デジタル化された意識は相続法上どのように扱われるのか。これらの問いは、国内の信託法や相続法との整合性だけでなく、**国際的な人権規約との衝突**の可能性も視野に入れた、より広範な検討を必要とすることを示唆している。本プロジェクトでは、これらの課題に対する具体的な法的シナリオを分析し、将来の法整備に向けた提言を行うことも視野に入れる。
                </p>
            </section>

            <!-- About -->
            <section class="section">
                <h2 class="section-title">About</h2>
                <p><strong>中田 康史 (Yasufumi Nakata)</strong><br>
                    慶應義塾大学 環境情報学部 / 青山敦研究室 所属。<br>
                    本サイトはマインドアップロード研究に関する公開研究ノートです。</p>
            </section>

            <!-- References -->
            <section class="section references">
                <h2 class="section-title">References</h2>
                <ol>
                    <li id="ref-1">Fleming, S. M., et al. (2023). Open letter regarding "The integrated information
                        theory of consciousness". <em>Neuroscience of Consciousness</em>, 2023(1), niad001. <a
                            href="https://doi.org/10.1093/nc/niad001">doi:10.1093/nc/niad001</a></li>
                    <li id="ref-2">Tononi, G., et al. (2016). Integrated information theory: from consciousness to its
                        physical substrate. <em>Nat. Rev. Neurosci.</em>, 17, 450–461. <a
                            href="https://doi.org/10.1038/nrn.2016.44">doi:10.1038/nrn.2016.44</a></li>
                    <li id="ref-3">Hanson, J. R. (2023). On the non-uniqueness problem in integrated information theory.
                        <em>Neuroscience of Consciousness</em>, 2023(1), niad014. <a
                            href="https://doi.org/10.1093/nc/niad014">doi:10.1093/nc/niad014</a>
                    </li>
                    <li id="ref-4">Parfit, D. (1984). <em>Reasons and Persons</em>. Oxford University Press.</li>
                    <li id="ref-5">Michel, C. M., & Brunet, D. (2019). EEG source imaging: a practical review of the
                        methodology. <em>Nature Reviews Neurology</em>, 15, 193–205. <a
                            href="https://doi.org/10.1038/s41582-019-0149-6">doi:10.1038/s41582-019-0149-6</a></li>
                    <li id="ref-7">Yamakawa, H., et al. (2024). Technology roadmap toward the completion of whole-brain
                        architecture with BRA-driven development. <em>Cognitive Systems Research</em>, 88, 101300. <a
                            href="https://doi.org/10.1016/j.cogsys.2024.101300">doi:10.1016/j.cogsys.2024.101300</a>
                    </li>
                    <li id="ref-8">Sandberg, A., & Bostrom, N. (2008). <em>Whole Brain Emulation: A Roadmap</em>. Future
                        of Humanity Institute, Oxford University. <a
                            href="https://www.fhi.ox.ac.uk/wp-content/uploads/Whole-Brain-Emulation-Roadmap-v1.2-web.pdf">Link</a>
                    </li>
                    <li id="ref-9">Logothetis, N. K. (2008). What we can do and what we cannot do with fMRI.
                        <em>Nature</em>, 453(7197), 869-878. <a
                            href="https://doi.org/10.1038/nature06976">doi:10.1038/nature06976</a>
                    </li>
                    <li id="ref-10">Yuste, R., et al. (2017). Four ethical priorities for neurotechnologies and AI.
                        <em>Nature</em>, 551(7679), 159-163. <a
                            href="https://doi.org/10.1038/551159a">doi:10.1038/551159a</a>
                    </li>
                    <li id="ref-11">Horikawa, T., et al. (2025). Mind captioning: Evolving descriptive text of mental
                        content from human brain activity. <em>Science Advances</em>, 11(45), eadw1464. <a
                            href="https://doi.org/10.1126/sciadv.adw1464">doi:10.1126/sciadv.adw1464</a></li>
                    <li id="ref-12">Kozlov, M. (2025). 'Mind-captioning' AI decodes brain activity to turn thoughts into
                        text. <em>Nature</em>. (Note: Future publication date as of Jan 12, 2026).</li>
                    <li id="ref-13">Friston, K. J., Harrison, L., & Penny, W. (2003). Dynamic causal modelling.
                        <em>NeuroImage</em>, 19(4), 1177-1202. <a
                            href="https://doi.org/10.1016/S1053-8119(03)00202-7">doi:10.1016/S1053-8119(03)00202-7</a>
                    </li>
                    <li id="ref-14">Friston, K. J., & Dolan, R. J. (2010). The free-energy principle in mind and brain.
                        <em>Nature Reviews Neuroscience</em>, 11(2), 127-138. <a
                            href="https://doi.org/10.1038/nrn2787">doi:10.1038/nrn2787</a>
                    </li>
                    <li id="ref-16">Markram, H. (2006). The Blue Brain Project. <em>Nature Reviews Neuroscience</em>,
                        7(2), 153-160. <a href="https://doi.org/10.1038/nrn1860">doi:10.1038/nrn1860</a></li>
                    <li id="ref-17">Albantakis, L., et al. (2023). Integrated information theory (IIT) 4.0: Formulating
                        the properties of phenomenal existence in physical terms. <em>PLOS Computational Biology</em>,
                        19(10), e1011465. <a
                            href="https://doi.org/10.1371/journal.pcbi.1011465">doi:10.1371/journal.pcbi.1011465</a>
                    </li>
                    <li id="ref-24">Schumer, C., et al. (2025). <em>Management of Individuals' Neural Data (MIND) Act of
                            2025</em>. U.S. Senate Bill. (Note: Proposed bill as of Jan 12, 2026).</li>
                    <li id="ref-27">Ienca, M., & Andorno, R. (2017). Towards new human rights in neuroscience. <em>Life
                            Sciences, Society and Policy</em>, 13(1), 5. <a
                            href="https://doi.org/10.1186/s40504-017-0050-1">doi:10.1186/s40504-017-0050-1</a></li>
                    <li id="ref-39">Jun, S., Altmann, A., Sadaghiani, S., et al. (2025). Modulatory Neurotransmitter
                        Genotypes Shape Dynamic
                        Functional Connectome Reconfigurations. <em>Journal of Neuroscience</em>, 45(9). <a
                            href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11884390/">PMC11884390</a></li>
                    <li id="ref-40">Doerig, A., et al. (2019). The unfolding argument: Why IIT and other causal
                        structure theories cannot explain consciousness. <em>Consciousness and Cognition</em>, 72,
                        102761. <a
                            href="https://doi.org/10.1016/j.concog.2019.04.004">doi:10.1016/j.concog.2019.04.004</a>
                    </li>
                    <li id="ref-41">Santello, M., et al. (2019). Astrocyte-neuron interactions: from synapses to
                        networks and behavior. <em>Neuron</em>, 103(6), 985-1000. <a
                            href="https://doi.org/10.1016/j.neuron.2019.08.024">doi:10.1016/j.neuron.2019.08.024</a>
                    </li>
                    <li id="ref-42">Melloni, L., et al. (2023). An adversarial collaboration protocol for testing
                        contrasting predictions of global neuronal workspace and integrated information theory. <em>PLoS
                            ONE</em>, 18(3), e0282855. <a
                            href="https://doi.org/10.1371/journal.pone.0282855">doi:10.1371/journal.pone.0282855</a>
                    </li>
                    <li id="ref-43">Dehaene, S., Kerszberg, M., & Changeux, J. P. (1998). A neuronal model of a global
                        workspace in effortful cognitive tasks. <em>Proceedings of the National Academy of
                            Sciences</em>, 95(24), 14529-14534. <a
                            href="https://doi.org/10.1073/pnas.95.24.14529">doi:10.1073/pnas.95.24.14529</a></li>
                    <li id="ref-44">Tononi, G. (2015). Integrated information theory. <em>Scholarpedia</em>, 10(1),
                        4164. <a
                            href="http://www.scholarpedia.org/article/Integrated_information_theory">doi:10.4249/scholarpedia.4164</a>
                        (Note: IITの内因的実在(Intrinsic Existence)の公理に関する議論については、この総説および[17]を参照)</li>
                    <li id="ref-45">Friston, K. (2010). The free-energy principle: a rough guide to the brain?.
                        <em>Nature reviews neuroscience</em>, 11(2), 127-138. <a
                            href="https://doi.org/10.1038/nrn2787">doi:10.1038/nrn2787</a>
                    </li>
                    <li id="ref-46">Parr, T., & Friston, K. J. (2019). Generalised free energy and active inference.
                        <em>Biological cybernetics</em>, 113(4), 495-513. <a
                            href="https://doi.org/10.1007/s00422-019-00803-8">doi:10.1007/s00422-019-00803-8</a>
                    </li>
                    <li id="ref-47">Casali, A. G., Gosseries, O., Rosanova, M., Boly, M., Sarasso, S., Casali, K. R.,
                        ... & Massimini, M. (2013). A theoretically based index of consciousness independent of sensory
                        processing and
                        behavior. <em>Science Translational Medicine</em>, 5(198), 198ra105. <a
                            href="https://doi.org/10.1126/scitranslmed.3006294">doi:10.1126/scitranslmed.3006294</a>
                    </li>
                    <li id="ref-48">No-Report Paradigms: Extracting the True Neural Correlates of Consciousness.
                        <em>PubMed</em> (PMID: 26585549). <a href="https://pubmed.ncbi.nlm.nih.gov/26585549/">Link</a>
                    </li>
                    <li id="ref-49">Breakdown of cortical effective connectivity during sleep. <a
                            href="https://air.unimi.it/handle/2434/15471">Link</a></li>
                    <li id="ref-50">Complexity of Multi-Dimensional Spontaneous EEG Decreases during Propofol Induced
                        General Anaesthesia. <em>PMC</em> (PMCID: PMC4529106). <a
                            href="https://pmc.ncbi.nlm.nih.gov/articles/PMC4529106/">Link</a></li>
                    <li id="ref-51">A fast and general method to empirically estimate the complexity of brain responses
                        to transcranial and intracranial stimulations. <em>PubMed</em> (PMID: 31133480). <a
                            href="https://pubmed.ncbi.nlm.nih.gov/31133480/">Link</a></li>
                    <li id="ref-52">Critical dynamics in spontaneous EEG predict anesthetic-induced loss of
                        consciousness and perturbational complexity. <em>Communications Biology</em>. <a
                            href="https://www.nature.com/articles/s42003-024-06613-8">Link</a></li>
                    <li id="ref-53">Brain Functional Connectivity as Biomarker for Propofol-Induced Alterations of
                        Consciousness. <em>PubMed</em> (PMID: 34891664). <a
                            href="https://pubmed.ncbi.nlm.nih.gov/34891664/">Link</a></li>
                    <li id="ref-54">Adversarial testing of global neuronal workspace and integrated information theories
                        of consciousness. <em>Nature</em>. <a
                            href="https://www.nature.com/articles/s41586-025-08888-1">Link</a></li>
                    <li id="ref-55">Detecting the Potential for Consciousness in Unresponsive Patients Using the
                        Perturbational Complexity Index. <em>Brain Sciences (MDPI)</em>. <a
                            href="https://www.mdpi.com/2076-3425/10/12/917">Link</a></li>
                    <li id="ref-56">Lu, J., et al. (2023). Criticality of resting-state EEG predicts perturbational
                        complexity and level of consciousness during anesthesia. *Communications Biology*, 6(1), 1-13.
                        <a href="https://www.nature.com/articles/s42003-024-06613-8">Link</a> (Note: This reference,
                        originally cited from a preprint, now points to the peer-reviewed publication and strengthens
                        the claims related to criticality and PCI).</li>
                    <li id="ref-57">Azevedo, F. A., Carvalho, L. R., Grinberg, L. T., Farfel, J. M., Ferretti, R. E.,
                        Leite, R. E., ... & Herculano-Houzel, S. (2009). Equal numbers of neuronal and nonneuronal cells
                        make the human brain an isometrically scaled-up primate brain. <em>Journal of Comparative
                            Neurology</em>, 513(5), 532-541. <a
                            href="https://doi.org/10.1002/cne.21974">doi:10.1002/cne.21974</a></li>
                    <li id="ref-58">Weber, C. (2025). The multiplicity objection against uploading optimism.
                        <em>Synthese</em>, 205. <a
                            href="https://doi.org/10.1007/s11229-025-05057-9">doi:10.1007/s11229-025-05057-9</a></li>
                    <li id="ref-59">Clowes, R. W. (2021). Slow Continuous Mind Uploading. In <em>The Palgrave Handbook
                            of Philosophy and Public Policy</em>. <a
                            href="https://doi.org/10.1007/978-3-030-72644-7_8">doi:10.1007/978-3-030-72644-7_8</a></li>
                    <li id="ref-60">Vaswani, A., et al. (2017). Attention Is All You Need. <em>Advances in Neural
                            Information Processing Systems (NeurIPS)</em>. <a
                            href="https://arxiv.org/abs/1706.03762">arXiv:1706.03762</a></li>
                    <li id="ref-61">Ouyang, L., et al. (2022). Training language models to follow instructions with
                        human feedback. <em>arXiv:2203.02155</em>. <a href="https://arxiv.org/abs/2203.02155">arXiv</a>
                    </li>
                    <li id="ref-62">Rafailov, R., et al. (2023). Direct Preference Optimization: Your Language Model is
                        Secretly a Reward Model. <em>arXiv:2305.18290</em>. <a
                            href="https://arxiv.org/abs/2305.18290">arXiv</a></li>
                    <li id="ref-63">Dettmers, T., et al. (2023). QLoRA: Efficient Finetuning of Quantized LLMs.
                        <em>arXiv:2305.14314</em>. <a href="https://arxiv.org/abs/2305.14314">arXiv</a></li>
                    <li id="ref-64">Lewis, P., et al. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP
                        Tasks. <em>arXiv:2005.11401</em>. <a href="https://arxiv.org/abs/2005.11401">arXiv</a></li>
                    <li id="ref-65">Yao, S., et al. (2022). ReAct: Synergizing Reasoning and Acting in Language Models.
                        <em>arXiv:2210.03629</em>. <a href="https://arxiv.org/abs/2210.03629">arXiv</a></li>
                    <li id="ref-66">Schick, T., et al. (2023). Toolformer: Language Models Can Teach Themselves to Use
                        Tools. <em>arXiv:2302.04761</em>. <a href="https://arxiv.org/abs/2302.04761">arXiv</a></li>
                    <li id="ref-67">Manakul, P., et al. (2023). SelfCheckGPT: Zero-Resource Black-Box Hallucination
                        Detection for Generative Large Language Models. <em>arXiv:2303.08896</em>. <a
                            href="https://arxiv.org/abs/2303.08896">arXiv</a></li>
                </ol>
            </section>

        </article>

        <!-- Sidebar -->
        <aside class="sidebar-column">

            <div class="key-points">
                <h4>Highlights</h4>
                <ul>
                    <li>IIT/GNWTなどの理論対立を実装要件に落とす</li>
                    <li>ESI逆問題の克服策（IHM・不確実性定量化）を明記</li>
                    <li>DCM/能動的推論でデコーディング→生成モデルへ拡張</li>
                    <li>EEG複雑性×摂動応答×臨界性で行動非依存の意識指標をロードマップ化</li>
                </ul>
            </div>

            <div class="sidebar-box">
                <h4>Study Overview</h4>
                <p><strong>Objective:</strong> マルチモーダル計測と神経解読を統合した「本人性維持」評価系の設計</p>
                <p style="margin-top:8px;"><strong>Design:</strong> 課題ベース＋安静時の縦断収集、侵襲/非侵襲データの比較</p>
            </div>

            <div class="sidebar-box">
                <h4>Focus Areas</h4>
                <ul>
                    <li>脳活動の計測（HD-EEG, ESI, fMRI）</li>
                    <li>計算論的神経科学（DCM, Transformer）</li>
                    <li>意識の理論（IIT, 心理的連続性）</li>
                    <li>倫理と法（Neurorights, MIND Act）</li>
                </ul>
            </div>

            <div class="sidebar-box">
                <h4>Consciousness Metrics (EEG)</h4>
                <ul>
                    <li>行動非依存の意識指標（PCI/PCI-ST）<sup><a href="#ref-47">[47]</a></sup></li>
                    <li>no-report設計でreport confoundを分離<sup><a href="#ref-48">[48]</a></sup></li>
                    <li>安静時の複雑性・臨界性指標の整備<sup><a href="#ref-50">[50]</a></sup><sup><a href="#ref-52">[52]</a></sup></li>
                    <li>臨床（鎮静/麻酔/重症）への一般化を重視<sup><a href="#ref-55">[55]</a></sup></li>
                </ul>
            </div>

            <div class="sidebar-box">
                <h4>Ethics & Governance</h4>
                <ul>
                    <li>MIND Act of 2025 (主に神経データプライバシー) 準拠の検討</li>
                    <li>Neurorights (Ienca & Andorno, 2017) の4つの権利を考慮<sup><a href="#ref-27">[27]</a></sup>:
                        <ul style="padding-left: 15px; margin-top: 4px; list-style-type: '— ';">
                            <li>精神的プライバシー権</li>
                            <li>認知的自由権</li>
                            <li>精神的完全性の権利</li>
                            <li>心理的連続性の権利</li>
                        </ul>
                    </li>
                    <li>デジタル人格権と、既存法（信託法、相続法）との整合性</li>
                </ul>
            </div>

            <div class="sidebar-box">
                <h4>Data Standards</h4>
                <ul>
                    <li>BIDS-EEG標準への準拠（<strong>課題:</strong> メタデータ拡充が急務）</li>
                    <li>データ構造とスキーマ例の公開</li>
                    <li>多施設間相互運用性の確保</li>
                </ul>
            </div>

            <div class="sidebar-box">
                <h4>Paper Collection</h4>
                <p>過去10年間の「Mind Uploading」に関する学術論文を収集・翻訳した資料を公開しています。</p>
                <a href="mind_uploading_papers.html"
                    style="display: inline-block; margin-top: 10px; font-weight: bold; color: var(--color-accent);">論文集を見る
                    (HTML) →</a>
            </div>

            <div class="cta-box">
                <h4>Contribute</h4>
                <p>このプロジェクトに参加しませんか？</p>
                <a href="https://github.com/yasufumi-nakata/eegflow/issues" target="_blank">Issue を立てる</a>
            </div>

        </aside>
    </main>

    <footer>
        <p>Mind Uploading Research · <a href="https://github.com/yasufumi-nakata/eegflow">GitHub</a></p>
    </footer>

</body>

</html>
